---
title: "Uncertainty Handling"
description: "How Nimbus manages uncertainty in neural signals for robust BCI applications"
icon: "shield"
---

# Uncertainty Handling in BCI

Neural signals are inherently uncertain. Signal quality varies, brain states change, and individual differences create significant variability. Traditional BCI systems ignore this uncertainty, leading to brittle performance and user frustration. Nimbus explicitly models and manages uncertainty to create robust, trustworthy BCI applications.

## Sources of Uncertainty in BCI

### Signal-Level Uncertainty

Neural recordings contain multiple sources of noise and variability:

<Columns cols={2}>
  <Card title="Measurement Noise" icon="signal">
    Electrical interference, amplifier noise, quantization errors
  </Card>
  <Card title="Biological Artifacts" icon="heartbeat">
    Eye blinks, muscle activity, cardiac signals, breathing
  </Card>
  <Card title="Environmental Factors" icon="globe">
    Temperature, humidity, electromagnetic interference
  </Card>
  <Card title="Electrode Issues" icon="link">
    Poor contact, impedance changes, electrode drift
  </Card>
</Columns>

### Cognitive Uncertainty

The brain itself introduces uncertainty:

- **State variability**: Attention, fatigue, mood affect neural patterns
- **Learning effects**: Brain patterns change as users adapt to the BCI
- **Individual differences**: Each person's brain is unique
- **Task complexity**: Difficult tasks produce more variable neural responses

### Model Uncertainty

BCI models have inherent limitations:

- **Training data**: Limited samples may not capture full variability
- **Model assumptions**: Simplified models miss complex neural dynamics
- **Generalization**: Performance on new users or conditions is uncertain
- **Temporal drift**: Models become outdated as brain patterns evolve

## Traditional Approaches vs. Nimbus

### Deterministic BCI Systems

Most current BCI systems ignore uncertainty and always provide a single answer with no confidence measure.

**Traditional approach:**
- Extract features from neural signals
- Apply classifier
- Return single class prediction
- No indication of reliability

**Problems:**
- **Overconfident**: Always provides an answer, even with poor signal quality
- **No adaptation**: Cannot adjust behavior based on uncertainty
- **Poor user experience**: Users can't tell when the system is struggling
- **Safety issues**: Critical applications need to know when predictions are unreliable

### Probabilistic Approach

Both SDKs model uncertainty explicitly through Bayesian inference:

<Tabs>
  <Tab title="Python">
```python
from nimbus_pysdk import NimbusLDA

# Train and predict
clf = NimbusLDA()
clf.fit(X_train, y_train)

# Returns full probability distribution
predictions = clf.predict(X_test)
probabilities = clf.predict_proba(X_test)

# Access predictions with uncertainty
for i, pred in enumerate(predictions):
    confidence = probabilities[i].max()
    posterior = probabilities[i]  # Full distribution
    
    # Confidence-based decision making
    if confidence > 0.9:
        # High confidence - execute immediately
        execute_command(pred)
    elif confidence > 0.7:
        # Medium confidence - show confirmation
        show_confirmation_dialog(pred, posterior)
    else:
        # Low confidence - request clearer signal
        request_better_signal()
```
  </Tab>
  <Tab title="Julia">
```julia
using NimbusSDK

# Returns full probability distribution
results = predict_batch(model, bci_data)

# Access predictions with uncertainty
for (i, pred) in enumerate(results.predictions)
    confidence = results.confidences[i]
    posterior = results.posteriors[:, i]  # Full distribution
    
    # Confidence-based decision making
    if confidence > 0.9
        # High confidence - execute immediately
        execute_command(pred)
    elseif confidence > 0.7
        # Medium confidence - show confirmation
        show_confirmation_dialog(pred, posterior)
    else
        # Low confidence - request clearer signal
        request_better_signal()
    end
end
```
  </Tab>
</Tabs>

**Benefits:**
- Full posterior probability distribution over classes
- Explicit confidence scores
- Can identify unreliable predictions
- Graceful handling of poor signal quality

## Types of Uncertainty

### Aleatoric Uncertainty (Data Uncertainty)

Irreducible uncertainty inherent in the data - cannot be reduced by collecting more training data.

**Example:** Noisy EEG signal

```julia
using NimbusSDK

# Assess signal quality
report = diagnose_preprocessing(bci_data)

if report.quality_score < 0.6
    @warn "High aleatoric uncertainty due to noise"
    println("SNR: $(report.snr_db) dB")
    println("Recommendations:")
    for rec in report.recommendations
        println("  â€¢ $rec")
    end
end
```

**Characteristics:**
- Cannot be reduced by more training data
- Varies across time and conditions
- Requires adaptive responses (reject trials, request better focus)

### Epistemic Uncertainty (Model Uncertainty)

Reducible uncertainty due to limited knowledge - can be reduced with more training data.

**Example:** New user with limited calibration

```julia
using NimbusSDK

# Check if user has sufficient training data
if n_training_trials < 50
    @warn "High epistemic uncertainty - insufficient training data"
    println("Recommendation: Collect more calibration trials")
end

# Calibrate model to reduce epistemic uncertainty
calib_model = calibrate_model(base_model, calib_data; iterations=20)
```

**Characteristics:**
- Can be reduced with more training data
- Higher for new users or novel conditions
- Decreases as the model learns

## Uncertainty Quantification Methods

### Confidence Measures

NimbusSDK provides multiple ways to quantify confidence:

**Posterior Entropy**: Measures how "spread out" the probability distribution is
- Low entropy = high confidence (distribution peaked on one class)
- High entropy = low confidence (distribution spread across classes)

**Maximum Probability**: The probability of the most likely prediction
- Values close to 1.0 = high confidence
- Values close to 1/n_classes = low confidence (random guessing)

**Quality Assessment**: Built-in trial quality scoring

```julia
using NimbusSDK

# Assess trial quality
quality = assess_trial_quality(results)

println("Overall score: $(quality.overall_score)")
println("Confidence acceptable: $(quality.confidence_acceptable)")
println("Recommendation: $(quality.recommendation)")

# Reject low-quality trials
if should_reject_trial(confidence, threshold=0.7)
    println("Trial rejected due to low confidence")
end
```

### Model Confidence in Practice

```julia
using NimbusSDK

# Analyze posterior distributions
for (i, pred) in enumerate(results.predictions)
    posterior = results.posteriors[:, i]
    confidence = results.confidences[i]
    
    # Entropy calculation (uncertainty measure)
    entropy = -sum(posterior .* log.(posterior .+ 1e-10))
    
    println("Trial $i:")
    println("  Prediction: $pred")
    println("  Confidence: $(round(confidence, digits=3))")
    println("  Entropy: $(round(entropy, digits=3))")
    println("  Posterior: $(round.(posterior, digits=3))")
end
```

## Adaptive Responses to Uncertainty

### Confidence-Based Actions

Adjust system behavior based on uncertainty levels:

- **High confidence (>0.9)**: Execute command immediately
- **Medium confidence (0.7-0.9)**: Show confirmation dialog with alternatives
- **Low confidence (0.5-0.7)**: Request clearer signal or additional focus
- **Very low confidence (&lt;0.5)**: Reject trial, suggest recalibration

### Dynamic Thresholds

Adjust decision thresholds based on application context:

- **Safety-critical** (wheelchair, prosthetics): High threshold (0.95+)
- **Gaming**: Lower threshold for responsiveness (0.7)
- **Communication aids**: Balanced threshold (0.8)
- **Research**: Variable based on study requirements

## User Interface for Uncertainty

### Visualizing Confidence

Help users understand system confidence through:

- **Color coding**: Green (high), yellow (medium), red (low confidence)
- **Confidence bars**: Visual indication of prediction strength
- **Alternative suggestions**: Show top K predictions when uncertain
- **Quality feedback**: Real-time signal quality indicators

### Progressive Disclosure

Show more information when uncertainty is high:
- Display alternative predictions
- Show confidence scores for each option
- Suggest actions to improve signal quality
- Provide feedback on current performance

## Clinical and Safety Applications

### Regulatory Requirements

For medical BCI devices, uncertainty quantification is essential:

<Note>
FDA and regulatory guidelines emphasize understanding when AI systems are uncertain. Probabilistic BCI systems provide the transparency needed for medical device approval.
</Note>

**Required documentation:**
- Session-level confidence scores
- Uncertainty event flagging
- Signal quality metrics
- Model version tracking
- Prediction audit trails

### Risk Management

Use uncertainty for risk assessment:

- **High-risk actions**: Require very high confidence (>0.95)
- **Medium-risk actions**: Standard confidence threshold (>0.8)
- **Low-risk actions**: Lower threshold acceptable (>0.7)
- **Monitoring**: Track confidence trends over time

## Getting Started with Uncertainty

Ready to build uncertainty-aware BCI applications?

<CardGroup cols={2}>
  <Card title="Probabilistic Models" icon="lightbulb" href="/core-concepts/probabilistic-ai">
    Learn about probabilistic AI for BCI
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/inference-endpoints">
    Explore uncertainty-aware APIs
  </Card>
  <Card title="Examples" icon="list" href="/examples/basic-examples">
    See uncertainty handling in practice
  </Card>
  <Card title="Error Handling & Validation" icon="check" href="/inference-configuration/error-handling">
    Validation, safeguards, and reliability patterns
  </Card>
</CardGroup>

---

<Note>
**Next**: Learn about [message passing architecture](/core-concepts/message-passing) that enables efficient probabilistic inference in Nimbus.
</Note>
