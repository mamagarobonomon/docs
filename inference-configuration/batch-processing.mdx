---
title: "Batch Processing"
description: "Configure offline analysis workflows for BCI research and model training"
icon: "list"
---

# Batch Processing for BCI

While streaming inference handles real-time applications, batch processing is essential for offline analysis, model training, research studies, and comprehensive data analysis. Nimbus provides powerful batch processing capabilities optimized for large-scale BCI datasets.

## When to Use Batch Processing

Batch processing is ideal for:

- **Model training and validation**
- **Offline data analysis and research**
- **Cross-subject studies and population analysis**
- **Feature exploration and selection**
- **Performance benchmarking**
- **Data preprocessing and cleaning**

<Note>
Batch processing trades real-time responsiveness for computational efficiency and the ability to process large datasets with complex algorithms.
</Note>

## Basic Batch Configuration

### Simple Batch Setup

```python
import nimbus

# Configure batch processing
batch_config = nimbus.BatchConfig(
    batch_size=32,              # Process 32 trials at once
    num_workers=4,              # Parallel processing
    device='gpu',               # Use GPU acceleration
    precision='float32',        # Standard precision
    memory_efficient=True       # Optimize for large datasets
)

# Create batch processor
processor = nimbus.BatchProcessor(batch_config)
```

### Dataset Loading

Load and prepare BCI datasets:

```python
# Load dataset
dataset = nimbus.load_dataset(
    path='/path/to/bci_data',
    format='edf',               # EDF, BDF, GDF, etc.
    subjects=['S01', 'S02', 'S03'],
    sessions=['session_1', 'session_2'],
    
    # Preprocessing
    preprocessing={
        'bandpass_filter': (0.5, 40),
        'notch_filter': 50,
        'rereferencing': 'average',
        'artifact_removal': 'ica'
    }
)

# Split dataset
train_data, val_data, test_data = dataset.split(
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    stratify=True  # Maintain class balance
)
```

## Batch Processing Workflows

### Model Training Workflow

Train BCI models on large datasets:

<AccordionGroup>
  <Accordion title="Supervised Learning">
    ```python
    # Supervised training workflow
    training_config = nimbus.TrainingConfig(
        model_type='probabilistic_classifier',
        algorithm='variational_bayes',
        
        # Training parameters
        max_epochs=100,
        batch_size=64,
        learning_rate=0.001,
        early_stopping=True,
        patience=10,
        
        # Regularization
        l2_regularization=0.01,
        dropout_rate=0.2,
        
        # Cross-validation
        cv_folds=5,
        cv_strategy='stratified'
    )
    
    # Train model
    model = processor.train_model(
        train_data=train_data,
        val_data=val_data,
        config=training_config
    )
    ```
  </Accordion>
  
  <Accordion title="Unsupervised Learning">
    ```python
    # Unsupervised learning for feature discovery
    unsupervised_config = nimbus.UnsupervisedConfig(
        method='variational_autoencoder',
        latent_dimensions=32,
        
        # Architecture
        encoder_layers=[128, 64, 32],
        decoder_layers=[32, 64, 128],
        
        # Training
        batch_size=128,
        max_epochs=200,
        beta=1.0,  # VAE beta parameter
        
        # Regularization
        kl_annealing=True,
        reconstruction_loss='mse'
    )
    
    # Learn representations
    representations = processor.learn_representations(
        data=unlabeled_data,
        config=unsupervised_config
    )
    ```
  </Accordion>
  
  <Accordion title="Transfer Learning">
    ```python
    # Transfer learning from pre-trained models
    transfer_config = nimbus.TransferConfig(
        base_model='pretrained_motor_imagery',
        
        # Fine-tuning strategy
        freeze_layers=['feature_extractor'],
        fine_tune_layers=['classifier'],
        
        # Training parameters
        initial_lr=0.0001,
        fine_tune_lr=0.00001,
        warmup_epochs=5,
        
        # Domain adaptation
        domain_adaptation=True,
        adaptation_method='coral'
    )
    
    # Transfer and fine-tune
    adapted_model = processor.transfer_learning(
        source_model=pretrained_model,
        target_data=new_subject_data,
        config=transfer_config
    )
    ```
  </Accordion>
</AccordionGroup>

### Analysis Workflows

Comprehensive BCI data analysis:

```python
# Analysis workflow configuration
analysis_config = nimbus.AnalysisConfig(
    analyses=[
        'spectral_analysis',
        'connectivity_analysis',
        'source_localization',
        'classification_analysis',
        'statistical_testing'
    ],
    
    # Statistical parameters
    significance_level=0.05,
    multiple_comparisons='fdr',
    bootstrap_iterations=1000,
    
    # Visualization
    generate_plots=True,
    plot_format='svg',
    save_results=True
)

# Run comprehensive analysis
results = processor.analyze_dataset(
    dataset=dataset,
    config=analysis_config
)
```

## Advanced Batch Features

### Parallel Processing

Leverage multiple cores and GPUs:

```python
# Multi-GPU batch processing
parallel_config = nimbus.ParallelConfig(
    # GPU configuration
    gpus=[0, 1, 2, 3],          # Use 4 GPUs
    gpu_memory_fraction=0.8,     # Use 80% of GPU memory
    
    # CPU configuration
    cpu_workers=16,              # CPU worker processes
    cpu_threads_per_worker=2,    # Threads per worker
    
    # Data loading
    data_loader_workers=8,       # Parallel data loading
    prefetch_factor=2,           # Prefetch batches
    pin_memory=True,             # Pin memory for GPU transfer
    
    # Load balancing
    dynamic_batching=True,       # Adjust batch sizes dynamically
    load_balancing='round_robin'
)

# Create parallel processor
parallel_processor = nimbus.ParallelBatchProcessor(parallel_config)
```

### Memory Optimization

Handle large datasets efficiently:

```python
# Memory-efficient processing
memory_config = nimbus.MemoryConfig(
    # Dataset handling
    lazy_loading=True,           # Load data on demand
    memory_mapping=True,         # Use memory mapping
    chunk_size='1GB',            # Process in chunks
    
    # Caching strategy
    cache_preprocessed=True,     # Cache preprocessing results
    cache_location='/tmp/nimbus_cache',
    cache_size_limit='10GB',
    
    # Memory monitoring
    memory_monitoring=True,
    memory_threshold=0.9,        # 90% memory usage limit
    garbage_collection='aggressive',
    
    # Optimization
    gradient_checkpointing=True, # Trade compute for memory
    mixed_precision=True         # Use mixed precision training
)

processor.configure_memory(memory_config)
```

### Distributed Processing

Scale across multiple machines:

```python
# Distributed batch processing
distributed_config = nimbus.DistributedConfig(
    # Cluster configuration
    master_node='192.168.1.100',
    worker_nodes=[
        '192.168.1.101',
        '192.168.1.102',
        '192.168.1.103'
    ],
    
    # Communication
    backend='nccl',              # NCCL for GPU communication
    communication_timeout=300,    # seconds
    
    # Data distribution
    data_sharding='subject',     # Shard by subject
    load_balancing=True,
    fault_tolerance=True,
    
    # Synchronization
    sync_strategy='all_reduce',
    gradient_compression=True
)

# Create distributed processor
distributed_processor = nimbus.DistributedBatchProcessor(distributed_config)
```

## Specialized Batch Operations

### Cross-Subject Analysis

Analyze patterns across multiple subjects:

```python
# Cross-subject analysis
cross_subject_config = nimbus.CrossSubjectConfig(
    # Subject handling
    subjects=dataset.get_subjects(),
    subject_normalization=True,
    
    # Analysis types
    analyses=[
        'individual_performance',
        'group_statistics',
        'subject_similarity',
        'population_patterns'
    ],
    
    # Statistical methods
    statistical_tests=[
        'anova',
        'permutation_test',
        'cluster_analysis'
    ],
    
    # Visualization
    generate_subject_plots=True,
    generate_group_plots=True
)

# Run cross-subject analysis
cross_subject_results = processor.cross_subject_analysis(
    dataset=dataset,
    config=cross_subject_config
)
```

### Feature Engineering

Automated feature discovery and selection:

```python
# Feature engineering pipeline
feature_config = nimbus.FeatureEngineeringConfig(
    # Feature extraction
    feature_types=[
        'spectral_features',
        'temporal_features',
        'spatial_features',
        'connectivity_features'
    ],
    
    # Feature selection
    selection_methods=[
        'mutual_information',
        'recursive_elimination',
        'lasso_regularization'
    ],
    
    # Feature validation
    cross_validation=True,
    stability_selection=True,
    
    # Optimization
    feature_optimization=True,
    max_features=100
)

# Engineer features
engineered_features = processor.engineer_features(
    data=train_data,
    config=feature_config
)
```

### Model Comparison

Compare different BCI approaches:

```python
# Model comparison study
comparison_config = nimbus.ModelComparisonConfig(
    models=[
        'linear_discriminant_analysis',
        'support_vector_machine',
        'random_forest',
        'neural_network',
        'probabilistic_classifier'
    ],
    
    # Evaluation metrics
    metrics=[
        'accuracy',
        'precision',
        'recall',
        'f1_score',
        'auc_roc',
        'information_transfer_rate'
    ],
    
    # Cross-validation
    cv_strategy='stratified_kfold',
    cv_folds=10,
    cv_repeats=5,
    
    # Statistical testing
    significance_testing=True,
    post_hoc_tests=True
)

# Run model comparison
comparison_results = processor.compare_models(
    data=dataset,
    config=comparison_config
)
```

## Batch Processing Pipelines

### Research Pipeline

Complete research workflow:

```python
# Research pipeline
research_pipeline = nimbus.ResearchPipeline([
    # Data preprocessing
    nimbus.PreprocessingStep(
        filters=['bandpass', 'notch'],
        artifact_removal='ica',
        rereferencing='average'
    ),
    
    # Feature extraction
    nimbus.FeatureExtractionStep(
        methods=['csp', 'spectral_power', 'connectivity'],
        optimization=True
    ),
    
    # Model training
    nimbus.ModelTrainingStep(
        algorithms=['lda', 'svm', 'probabilistic'],
        hyperparameter_optimization=True
    ),
    
    # Evaluation
    nimbus.EvaluationStep(
        cross_validation=True,
        statistical_testing=True,
        visualization=True
    ),
    
    # Reporting
    nimbus.ReportingStep(
        generate_report=True,
        export_results=True
    )
])

# Execute pipeline
pipeline_results = research_pipeline.execute(dataset)
```

### Production Pipeline

Model deployment preparation:

```python
# Production pipeline
production_pipeline = nimbus.ProductionPipeline([
    # Data validation
    nimbus.DataValidationStep(
        quality_checks=True,
        schema_validation=True
    ),
    
    # Model training
    nimbus.ProductionTrainingStep(
        algorithm='probabilistic_classifier',
        optimization='production',
        validation='holdout'
    ),
    
    # Model validation
    nimbus.ModelValidationStep(
        performance_tests=True,
        robustness_tests=True,
        safety_checks=True
    ),
    
    # Model packaging
    nimbus.ModelPackagingStep(
        format='onnx',
        optimization='inference',
        quantization=True
    ),
    
    # Deployment preparation
    nimbus.DeploymentPrepStep(
        containerization=True,
        documentation=True,
        monitoring_setup=True
    )
])

# Execute production pipeline
production_model = production_pipeline.execute(dataset)
```

## Performance Monitoring

### Batch Job Monitoring

Monitor long-running batch jobs:

```python
# Job monitoring
monitor = nimbus.BatchMonitor(
    metrics=['progress', 'throughput', 'memory_usage', 'gpu_utilization'],
    update_interval=30,  # seconds
    
    # Alerts
    alert_conditions={
        'memory_usage': 0.9,
        'gpu_temperature': 85,
        'job_stalled': 300  # seconds
    },
    
    # Logging
    log_level='INFO',
    log_file='/var/log/nimbus_batch.log'
)

# Start monitoring
monitor.start()

# Run batch job with monitoring
results = processor.process_batch(
    data=large_dataset,
    monitor=monitor
)
```

### Resource Utilization

Optimize resource usage:

```python
# Resource optimization
resource_config = nimbus.ResourceConfig(
    # CPU optimization
    cpu_optimization='throughput',
    numa_awareness=True,
    
    # GPU optimization
    gpu_optimization='memory',
    tensor_core_usage=True,
    
    # Memory optimization
    memory_optimization='bandwidth',
    huge_pages=True,
    
    # I/O optimization
    io_optimization='sequential',
    prefetch_data=True
)

processor.optimize_resources(resource_config)
```

## Best Practices

### Reproducibility

Ensure reproducible batch processing:

```python
# Reproducibility configuration
reproducibility_config = nimbus.ReproducibilityConfig(
    # Random seeds
    random_seed=42,
    deterministic_algorithms=True,
    
    # Environment tracking
    track_environment=True,
    track_dependencies=True,
    track_hardware=True,
    
    # Data versioning
    data_versioning=True,
    model_versioning=True,
    
    # Experiment tracking
    experiment_tracking=True,
    metadata_logging=True
)

processor.configure_reproducibility(reproducibility_config)
```

### Error Handling

Robust error handling for long-running jobs:

```python
# Robust batch processing
try:
    results = processor.process_batch(
        data=dataset,
        checkpoint_interval=100,  # Save progress every 100 batches
        resume_from_checkpoint=True,
        max_retries=3
    )
except nimbus.OutOfMemoryError:
    # Reduce batch size and retry
    processor.reduce_batch_size(factor=0.5)
    results = processor.process_batch(data=dataset)
    
except nimbus.ComputeError as e:
    # Log error and continue with fallback
    logger.error(f"Compute error: {e}")
    results = processor.process_batch_cpu_fallback(data=dataset)
```

## Integration Examples

### Research Study

Complete BCI research study:

```python
# Multi-subject motor imagery study
study_config = nimbus.StudyConfig(
    name="Motor Imagery Classification Study",
    subjects=20,
    sessions_per_subject=3,
    
    # Experimental design
    paradigm='motor_imagery',
    classes=['left_hand', 'right_hand', 'feet', 'tongue'],
    trials_per_class=100,
    
    # Analysis pipeline
    preprocessing='standard',
    feature_extraction='csp_spectral',
    classification='probabilistic',
    
    # Statistical analysis
    statistical_tests=True,
    multiple_comparisons_correction=True,
    
    # Reporting
    generate_figures=True,
    export_data=True
)

# Execute study
study_results = nimbus.execute_study(study_config)
```

### Clinical Validation

Clinical BCI system validation:

```python
# Clinical validation pipeline
clinical_config = nimbus.ClinicalConfig(
    # Regulatory requirements
    fda_compliance=True,
    gcp_compliance=True,
    
    # Validation protocol
    validation_type='prospective',
    primary_endpoint='classification_accuracy',
    secondary_endpoints=['itr', 'usability', 'safety'],
    
    # Statistical plan
    power_analysis=True,
    sample_size_calculation=True,
    interim_analysis=True,
    
    # Quality assurance
    data_monitoring=True,
    audit_trail=True,
    source_data_verification=True
)

# Run clinical validation
clinical_results = nimbus.clinical_validation(
    data=clinical_dataset,
    config=clinical_config
)
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Error Handling" icon="shield" href="/inference-configuration/error-handling">
    Implement robust error recovery
  </Card>
  <Card title="Real-time Setup" icon="cog" href="/inference-configuration/real-time-setup">
    Configure real-time processing
  </Card>
  <Card title="Streaming Inference" icon="signal" href="/inference-configuration/streaming-inference">
    Learn about continuous processing
  </Card>
  <Card title="Examples" icon="list" href="/examples/basic-examples">
    See batch processing examples
  </Card>
</CardGroup>

---

<Note>
**Next**: Learn how to implement [error handling](/inference-configuration/error-handling) for robust BCI applications.
</Note>
