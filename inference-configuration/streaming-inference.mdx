---
title: "Streaming Inference"
description: "Process continuous neural data streams with reactive message passing"
icon: "play"
---

# Streaming Inference for BCI

Streaming inference is the cornerstone of real-time BCI applications. Unlike batch processing that waits for complete data windows, streaming inference processes neural signals as they arrive, enabling truly responsive brain-computer interfaces with minimal latency.

## Streaming vs Batch Processing

### Traditional Batch Processing

Most BCI systems use batch processing:

```python
# Traditional batch approach
def batch_bci_processing(eeg_buffer):
    # Wait for complete window (e.g., 1 second)
    if len(eeg_buffer) >= window_size:
        features = extract_features(eeg_buffer)
        prediction = classify(features)
        return prediction
    else:
        return None  # Wait for more data
```

**Limitations:**
- High latency (must wait for complete windows)
- Inefficient (reprocesses overlapping data)
- Poor responsiveness (delayed reactions to brain state changes)

### Nimbus Streaming Approach

Streaming inference processes data incrementally:

```python
# Nimbus streaming approach
async def streaming_bci_inference(eeg_stream):
    async for sample in eeg_stream:
        # Process each sample immediately
        updated_belief = await nimbus.update_belief(sample)
        
        # Emit prediction when confidence is sufficient
        if updated_belief.confidence > threshold:
            yield updated_belief.prediction
```

**Advantages:**
- Ultra-low latency (processes samples immediately)
- Efficient (incremental updates, no recomputation)
- Responsive (adapts to rapid brain state changes)

## Setting Up Streaming Inference

### Basic Streaming Configuration

```python
import nimbus
import asyncio

# Configure streaming inference
stream_config = nimbus.StreamingConfig(
    sample_rate=1000,           # Hz
    channels=64,                # EEG channels
    buffer_size=16,             # Minimal buffering
    update_mode='incremental',  # Process each sample
    output_rate='adaptive'      # Emit when ready
)

# Create streaming processor
processor = nimbus.StreamingProcessor(stream_config)
```

### Data Source Integration

Connect to various BCI hardware:

<Tabs>
  <Tab title="OpenBCI">
    ```python
    # OpenBCI integration
    from nimbus.hardware import OpenBCIStream
    
    eeg_stream = OpenBCIStream(
        board_id=0,
        serial_port='/dev/ttyUSB0',
        sample_rate=250
    )
    
    # Start streaming
    async for sample in eeg_stream:
        result = await processor.process(sample)
        if result:
            print(f"Prediction: {result.prediction}")
    ```
  </Tab>
  
  <Tab title="Emotiv EPOC">
    ```python
    # Emotiv EPOC integration
    from nimbus.hardware import EmotivStream
    
    eeg_stream = EmotivStream(
        user_id='your_user_id',
        client_id='your_client_id',
        client_secret='your_secret'
    )
    
    await processor.connect_stream(eeg_stream)
    ```
  </Tab>
  
  <Tab title="Lab Streaming Layer">
    ```python
    # LSL integration
    from nimbus.hardware import LSLStream
    
    eeg_stream = LSLStream(
        stream_name='EEG',
        stream_type='EEG',
        timeout=5.0
    )
    
    await processor.connect_stream(eeg_stream)
    ```
  </Tab>
  
  <Tab title="Custom Hardware">
    ```python
    # Custom hardware integration
    class CustomEEGStream:
        async def __aiter__(self):
            while True:
                # Read from your hardware
                sample = await self.read_sample()
                yield sample
    
    custom_stream = CustomEEGStream()
    await processor.connect_stream(custom_stream)
    ```
  </Tab>
</Tabs>

## Streaming Processing Pipeline

### Incremental Feature Extraction

Process features as data arrives:

```python
# Configure incremental feature extraction
feature_config = nimbus.IncrementalFeatures(
    # Spectral features
    power_bands=[(8, 12), (13, 30)],  # Alpha, Beta
    update_method='exponential_smoothing',
    smoothing_factor=0.1,
    
    # Spatial features
    spatial_filters=['CSP', 'Laplacian'],
    filter_update='adaptive',
    
    # Temporal features
    temporal_window=1.0,  # seconds
    overlap=0.5,          # 50% overlap
    update_rate='continuous'
)

processor.configure_features(feature_config)
```

### Probabilistic State Tracking

Track brain states continuously:

```python
# Configure probabilistic state tracking
state_config = nimbus.StateTracking(
    states=['rest', 'left_hand', 'right_hand', 'feet'],
    transition_model='markov',
    observation_model='gaussian_mixture',
    
    # Streaming parameters
    belief_update='bayesian',
    memory_length=5.0,      # seconds
    adaptation_rate=0.05,
    
    # Uncertainty handling
    confidence_threshold=0.8,
    uncertainty_penalty=0.1
)

processor.configure_state_tracking(state_config)
```

### Output Generation

Configure when and how to emit predictions:

```python
# Configure output generation
output_config = nimbus.OutputConfig(
    # Emission criteria
    confidence_threshold=0.75,
    stability_window=0.2,    # seconds
    minimum_interval=0.1,    # seconds between outputs
    
    # Output format
    include_confidence=True,
    include_alternatives=True,
    include_timing=True,
    
    # Post-processing
    smoothing='exponential',
    debouncing=True,
    hysteresis_margin=0.1
)

processor.configure_output(output_config)
```

## Advanced Streaming Features

### Multi-Modal Streaming

Combine multiple data streams:

```python
# Multi-modal streaming setup
multimodal_config = nimbus.MultiModalConfig(
    primary_stream='EEG',
    secondary_streams=['EMG', 'EOG', 'Accelerometer'],
    
    # Synchronization
    sync_method='timestamp',
    max_delay=10,  # ms
    interpolation='linear',
    
    # Fusion strategy
    fusion_method='early',  # or 'late', 'hybrid'
    weights={'EEG': 0.7, 'EMG': 0.2, 'EOG': 0.1}
)

# Create multi-modal processor
multimodal_processor = nimbus.MultiModalProcessor(multimodal_config)
```

### Adaptive Processing

Automatically adjust processing based on conditions:

```python
# Adaptive processing configuration
adaptive_config = nimbus.AdaptiveConfig(
    # Signal quality adaptation
    quality_monitoring=True,
    quality_threshold=0.6,
    quality_actions={
        'low': 'increase_smoothing',
        'medium': 'standard_processing',
        'high': 'reduce_latency'
    },
    
    # Performance adaptation
    latency_monitoring=True,
    target_latency=15,  # ms
    adaptation_actions={
        'high_latency': 'reduce_precision',
        'low_latency': 'increase_accuracy'
    },
    
    # User state adaptation
    fatigue_detection=True,
    attention_monitoring=True,
    adaptation_learning=True
)

processor.enable_adaptive_processing(adaptive_config)
```

### Stream Buffering and Windowing

Optimize buffering for different BCI paradigms:

<AccordionGroup>
  <Accordion title="Motor Imagery">
    ```python
    # Motor imagery streaming
    mi_config = nimbus.StreamingConfig(
        paradigm='motor_imagery',
        
        # Buffering
        buffer_size=32,           # samples
        overlap=0.75,             # 75% overlap
        
        # Processing windows
        short_window=0.5,         # seconds (fast detection)
        long_window=2.0,          # seconds (accurate classification)
        
        # Output timing
        min_decision_time=0.3,    # seconds
        max_decision_time=1.0     # seconds
    )
    ```
  </Accordion>
  
  <Accordion title="P300 Speller">
    ```python
    # P300 streaming
    p300_config = nimbus.StreamingConfig(
        paradigm='p300',
        
        # Event-based processing
        event_detection=True,
        pre_stimulus=0.1,         # seconds
        post_stimulus=0.8,        # seconds
        
        # Averaging
        online_averaging=True,
        averaging_window=10,      # trials
        
        # Decision making
        confidence_accumulation=True,
        decision_threshold=0.9
    )
    ```
  </Accordion>
  
  <Accordion title="SSVEP">
    ```python
    # SSVEP streaming
    ssvep_config = nimbus.StreamingConfig(
        paradigm='ssvep',
        
        # Frequency analysis
        frequency_resolution=0.25,  # Hz
        analysis_window=1.0,        # seconds
        update_interval=0.1,        # seconds
        
        # Target frequencies
        targets=[6.0, 7.5, 8.57, 10.0, 12.0],
        harmonics=3,
        
        # Detection
        snr_threshold=2.0,
        stability_check=True
    )
    ```
  </Accordion>
</AccordionGroup>

## Performance Optimization

### Memory Management

Optimize memory usage for continuous operation:

```python
# Memory optimization
memory_config = nimbus.MemoryConfig(
    # Buffer management
    circular_buffers=True,
    buffer_pool_size=100,
    zero_copy_operations=True,
    
    # Garbage collection
    gc_strategy='incremental',
    gc_threshold=0.8,  # 80% memory usage
    
    # Memory limits
    max_memory_usage='1GB',
    emergency_cleanup=True,
    
    # Caching
    feature_cache_size=1000,
    model_cache_size=10
)

processor.configure_memory(memory_config)
```

### CPU and GPU Optimization

Leverage hardware acceleration:

```python
# Hardware acceleration
hardware_config = nimbus.HardwareConfig(
    # CPU optimization
    cpu_threads=4,
    cpu_affinity=[0, 1, 2, 3],
    simd_instructions=True,
    
    # GPU acceleration
    use_gpu=True,
    gpu_device=0,
    gpu_memory_fraction=0.5,
    gpu_streams=2,
    
    # Parallel processing
    pipeline_parallelism=True,
    data_parallelism=False,  # Not suitable for streaming
    
    # Optimization flags
    fast_math=True,
    tensor_cores=True  # If available
)

processor.configure_hardware(hardware_config)
```

## Error Handling and Reliability

### Stream Interruption Handling

Handle data stream interruptions gracefully:

```python
# Robust streaming with error handling
async def robust_streaming():
    retry_config = nimbus.RetryConfig(
        max_retries=3,
        backoff_strategy='exponential',
        base_delay=0.1,  # seconds
        max_delay=2.0    # seconds
    )
    
    try:
        async for sample in eeg_stream:
            try:
                result = await processor.process(sample)
                if result:
                    await handle_prediction(result)
            except nimbus.ProcessingError as e:
                await handle_processing_error(e)
                
    except nimbus.StreamInterruption as e:
        # Attempt to reconnect
        await reconnect_stream(retry_config)
        
    except nimbus.HardwareError as e:
        # Switch to backup hardware or graceful degradation
        await switch_to_backup(e)
```

### Quality Monitoring

Monitor stream quality in real-time:

```python
# Stream quality monitoring
quality_monitor = nimbus.StreamQualityMonitor(
    metrics=['signal_quality', 'artifact_level', 'electrode_impedance'],
    thresholds={
        'signal_quality': 0.7,
        'artifact_level': 0.3,
        'electrode_impedance': 50000  # ohms
    },
    
    # Actions on quality issues
    actions={
        'low_signal_quality': 'increase_smoothing',
        'high_artifacts': 'enable_artifact_removal',
        'high_impedance': 'alert_user'
    }
)

# Start monitoring
await quality_monitor.start()
```

## Real-World Examples

### Gaming BCI

Ultra-responsive gaming interface:

```python
# Gaming BCI streaming setup
gaming_config = nimbus.StreamingConfig(
    target_latency=8,           # ms - gaming requires ultra-low latency
    confidence_threshold=0.6,   # Lower threshold for responsiveness
    smoothing_factor=0.05,      # Minimal smoothing
    
    # Gaming-specific features
    gesture_detection=True,
    rapid_commands=True,
    multi_class_output=True,
    
    # Performance optimization
    precision='float16',
    batch_size=1,
    gpu_acceleration=True
)

gaming_processor = nimbus.StreamingProcessor(gaming_config)

# Process gaming commands
async for command in gaming_processor.stream():
    game_engine.execute_command(command)
```

### Medical Assistive Device

Reliable assistive technology:

```python
# Medical device streaming setup
medical_config = nimbus.StreamingConfig(
    target_latency=20,          # ms - balance speed and accuracy
    confidence_threshold=0.9,   # High threshold for safety
    redundancy=True,            # Multiple confirmation
    
    # Medical-specific features
    safety_monitoring=True,
    error_logging=True,
    audit_trail=True,
    
    # Reliability features
    watchdog_timer=True,
    failsafe_mode=True,
    backup_processing=True
)

medical_processor = nimbus.StreamingProcessor(medical_config)

# Process medical commands with safety checks
async for command in medical_processor.stream():
    if command.confidence > 0.95:
        medical_device.execute_command(command)
    else:
        request_user_confirmation(command)
```

## Monitoring and Debugging

### Real-time Metrics

Monitor streaming performance:

```python
# Performance monitoring
metrics = processor.get_streaming_metrics()
print(f"Processing latency: {metrics.avg_latency:.1f}ms")
print(f"Throughput: {metrics.samples_per_second:.0f} samples/s")
print(f"Buffer utilization: {metrics.buffer_utilization:.1%}")
print(f"Prediction rate: {metrics.predictions_per_second:.1f}/s")
```

### Stream Visualization

Visualize streaming data and predictions:

```python
# Real-time visualization
visualizer = nimbus.StreamVisualizer(
    plots=['raw_signal', 'features', 'predictions', 'confidence'],
    update_rate=10,  # Hz
    window_length=5  # seconds
)

# Start visualization
await visualizer.start()
```

## Best Practices

<Tip>
**Start Simple**: Begin with basic streaming configuration and gradually add complexity as needed. Monitor performance at each step.
</Tip>

1. **Buffer Sizing**: Use minimal buffers for low latency, but ensure stability
2. **Quality Monitoring**: Always monitor signal quality and adapt processing accordingly  
3. **Error Handling**: Implement robust error handling for production systems
4. **Performance Testing**: Regularly benchmark your streaming setup under realistic conditions
5. **User Feedback**: Provide real-time feedback to users about system status and confidence

## Next Steps

<CardGroup cols={2}>
  <Card title="Batch Processing" icon="layers" href="/inference-configuration/batch-processing">
    Learn about offline analysis workflows
  </Card>
  <Card title="Error Handling" icon="shield" href="/inference-configuration/error-handling">
    Implement robust error recovery
  </Card>
  <Card title="Real-time Setup" icon="cog" href="/inference-configuration/real-time-setup">
    Optimize system configuration
  </Card>
  <Card title="Examples" icon="list" href="/examples/basic-examples">
    See streaming inference in action
  </Card>
</CardGroup>

---

<Note>
**Next**: Learn how to configure [batch processing](/inference-configuration/batch-processing) for offline BCI analysis and model training.
</Note>
