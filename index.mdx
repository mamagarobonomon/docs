---
title: "Nimbus BCI Engine"
description: "Bayesian inference for Brain-Computer Interfaces in Python and Julia"
icon: "brain"
---

_Production-ready Bayesian BCI inference with Bayesian LDA, Bayesian GMM, and Bayesian Softmax models_

Nimbus provides fast, probabilistic inference for Brain-Computer Interface applications in **Python** and **Julia**. The SDKs deliver sub-20ms inference latency with full uncertainty quantification through **Bayesian LDA**, **Bayesian GMM**, and **Bayesian Softmax/MPR** implementations.

**Choose your SDK:**
- üêç **Python SDK** (`nimbus-bci`): sklearn-compatible classifiers with MNE-Python integration
- ‚ö° **Julia SDK** (`NimbusSDK.jl`): Built on RxInfer.jl for maximum performance

## Why Nimbus BCI

Brain-Computer Interfaces face unique challenges: noisy neural signals, inherent uncertainty, real-time requirements, and the need for explainability in medical applications.

**Current BCI Challenges:**
- **High Latency**: Standard processing takes 200ms+ for trial classification
- **No Uncertainty Quantification**: Deterministic outputs without confidence measures
- **Limited Adaptability**: Cannot handle changing brain states or signal quality
- **Black Box Models**: Deep learning lacks explainability for FDA approval

**Nimbus Solution:**
- ‚úÖ **Fast Inference**: 10-20ms per trial with Bayesian models
- ‚úÖ **Uncertainty Quantification**: Full posterior distributions, not just point estimates
- ‚úÖ **Training & Calibration**: Subject-specific personalization in minutes
- ‚úÖ **Explainable**: White-box probabilistic models for medical compliance
- ‚úÖ **Production-Ready**: Batch and streaming modes, quality assessment, performance tracking

<CardGroup cols={2}>
  <Card
    title="Python SDK Quickstart"
    icon="python"
    href="/python-sdk/quickstart"
    horizontal
  >
    Get started with nimbus-bci in Python
  </Card>
  <Card
    title="Julia SDK Quickstart"
    icon="code"
    href="/quickstart"
    horizontal
  >
    Get started with NimbusSDK.jl in Julia
  </Card>
</CardGroup>

## Core Features

<CardGroup cols={2}>
  <Card
    title="Fast Bayesian Inference"
    icon="zap"
    href="/core-concepts/probabilistic-ai"
  >
    Bayesian LDA and Bayesian GMM models with 10-20ms inference latency using RxInfer.jl reactive message passing
  </Card>
  <Card
    title="Training & Calibration"
    icon="graduation-cap"
    href="/examples/advanced-applications"
  >
    Train custom models on your data or calibrate pre-trained models with 10-20 trials per subject
  </Card>
  <Card
    title="Real-time Streaming"
    icon="activity"
    href="/inference-configuration/streaming-inference"
  >
    Process EEG chunks as they arrive with chunk-by-chunk inference and weighted aggregation
  </Card>
  <Card
    title="Uncertainty Quantification"
    icon="shield-check"
    href="/core-concepts/uncertainty-handling"
  >
    Full posterior distributions with confidence scores for quality assessment and rejection
  </Card>
</CardGroup>

## Implemented Models

Both SDKs provide three production-ready Bayesian models:

<CardGroup cols={3}>
  <Card
    title="Bayesian LDA"
    icon="brain"
    href="/models/rxlda"
  >
    **Bayesian Linear Discriminant Analysis** with shared covariance. Fast (10-15ms), efficient, ideal for well-separated classes like motor imagery. Python: `NimbusLDA`, Julia: `RxLDAModel`.
  </Card>
  <Card
    title="Bayesian GMM"
    icon="brain"
    href="/models/rxgmm"
  >
    **Bayesian Gaussian Mixture Model** with class-specific covariances. More flexible (15-25ms), better for overlapping distributions like P300. Python: `NimbusGMM`, Julia: `RxGMMModel`.
  </Card>
  <Card
    title="Bayesian Softmax/MPR"
    icon="brain"
    href="/models/rxpolya"
  >
    **Bayesian Multinomial Logistic Regression** with continuous transitions. Most flexible (15-25ms), ideal for complex multinomial classification tasks. Python: `NimbusSoftmax`, Julia: `RxPolyaModel`.
  </Card>
</CardGroup>

## BCI Paradigms Supported

<CardGroup cols={3}>
  <Card
    title="Motor Imagery"
    icon="hand"
  >
    **2-4 class classification**
    - Left/right hand
    - Hands/feet/tongue
    - 70-90% accuracy
    - RxLDA recommended
  </Card>
  <Card
    title="P300"
    icon="eye"
  >
    **Binary classification**
    - Target/non-target
    - Speller applications
    - 80-95% accuracy
    - RxGMM recommended
  </Card>
  <Card
    title="SSVEP"
    icon="bolt"
  >
    **Multi-class frequency**
    - 2-6 target frequencies
    - High accuracy (85-98%)
    - Works with both models
  </Card>
</CardGroup>

## Quick Example

<Tabs>
  <Tab title="Python">
```python
from nimbus_pysdk import NimbusLDA
import numpy as np

# 1. Create and fit classifier
clf = NimbusLDA()
clf.fit(X_train, y_train)

# 2. Predict with uncertainty
predictions = clf.predict(X_test)
probabilities = clf.predict_proba(X_test)

# 3. Works with sklearn pipelines
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

pipe = make_pipeline(StandardScaler(), NimbusLDA())
pipe.fit(X_train, y_train)

# 4. Online learning
clf.partial_fit(X_new, y_new)
```
  </Tab>
  <Tab title="Julia">
```julia
using NimbusSDK

# 1. One-time setup: Install core with your API key
NimbusSDK.install_core("nbci_live_your_key")

# 2. Load pre-trained model
model = load_model(RxLDAModel, "motor_imagery_4class_v1")

# 3. Prepare preprocessed features (CSP, bandpower, etc.)
data = BCIData(csp_features, metadata, labels)

# 4. Run inference
results = predict_batch(model, data)

# 5. Analyze
println("Accuracy: $(sum(results.predictions .== labels) / length(labels))")
println("Mean confidence: $(mean(results.confidences))")
println("ITR: $(calculate_ITR(accuracy, 4, 4.0)) bits/minute")
```
  </Tab>
</Tabs>

## Use Cases

<CardGroup cols={2}>
  <Card
    title="Assistive Technologies"
    icon="accessibility"
    href="/examples/industry-use-cases"
  >
    Wheelchair control, prosthetic limbs, communication devices with explainable, FDA-ready probabilistic models
  </Card>
  <Card
    title="Research Platforms"
    icon="flask"
    href="/examples/basic-examples"
  >
    Academic research with training capabilities, subject-specific calibration, and comprehensive performance metrics
  </Card>
  <Card
    title="Neurofeedback"
    icon="cpu"
    href="/inference-configuration/real-time-setup"
  >
    Real-time brain state monitoring with streaming inference and confidence-based quality control
  </Card>
  <Card
    title="Gaming & Wellness"
    icon="gamepad"
    href="/examples/advanced-applications"
  >
    Low-latency brain control for immersive experiences with adaptive difficulty based on confidence
  </Card>
</CardGroup>

## SDK Architecture

```
EEG Hardware ‚Üí Preprocessing ‚Üí Nimbus SDK ‚Üí Application
   (LSL/BrainFlow)  (MNE/EEGLAB)  (Python/Julia)  (Your Code)
```

**Key Design:**
- **Local Inference**: All processing on your machine (Python SDK is fully local)
- **Privacy**: Your EEG data never leaves your computer
- **Speed**: No network latency, consistent &lt;20ms performance
- **Offline Capable**: Python SDK works completely offline

**Julia SDK API Role:**
- Authentication and licensing
- Pre-trained model distribution
- Optional analytics logging

## Getting Started

<Tabs>
  <Tab title="Python">
<Steps>
  <Step title="Install Python SDK">
    ```bash
    pip install nimbus-bci
    ```
  </Step>
  <Step title="Preprocess EEG">
    Use MNE-Python to extract features (CSP, bandpower, ERP)
  </Step>
  <Step title="Train & Predict">
    Use sklearn-compatible API to train models and make predictions
  </Step>
  <Step title="Deploy">
    Integrate with sklearn pipelines, streaming inference, or real-time applications
  </Step>
</Steps>
  </Tab>
  <Tab title="Julia">
<Steps>
  <Step title="Install Julia SDK">
    ```julia
    using Pkg
    Pkg.add("NimbusSDK")
    
    # One-time setup: Install core with your API key
    using NimbusSDK
    NimbusSDK.install_core("your-api-key")
    ```
  </Step>
  <Step title="Get API Key">
    Contact **hello@nimbusbci.com** for your API key and license tier
  </Step>
  <Step title="Preprocess EEG">
    Use MNE-Python, EEGLAB, or your tool to extract features (CSP, bandpower, ERP)
  </Step>
  <Step title="Run Inference">
    Load model, process features, get predictions with confidence scores
  </Step>
</Steps>
  </Tab>
</Tabs>

## Documentation

<CardGroup cols={3}>
  <Card
    title="Python SDK"
    icon="python"
    href="/python-sdk/introduction"
  >
    sklearn-compatible Bayesian classifiers
  </Card>
  <Card
    title="Julia SDK"
    icon="code"
    href="/api-reference/julia-sdk"
  >
    RxInfer.jl-based inference engine
  </Card>
  <Card
    title="Model Training"
    icon="graduation-cap"
    href="/examples/advanced-applications"
  >
    Train custom models on your data
  </Card>
  <Card
    title="Preprocessing Guide"
    icon="list-filter"
    href="/inference-configuration/preprocessing-requirements"
  >
    Required EEG preprocessing steps
  </Card>
  <Card
    title="Code Examples"
    icon="braces"
    href="/examples/code-samples"
  >
    Working Python and Julia examples
  </Card>
  <Card
    title="API Reference"
    icon="server"
    href="/api-reference/authentication"
  >
    Authentication and model registry
  </Card>
</CardGroup>

## Performance

| Metric | RxLDA | RxGMM | Bayesian MPR |
|--------|-------|-------|--------------|
| **Inference Latency** | 10-15ms | 15-25ms | 15-25ms |
| **Training Time** | 10-30s | 15-40s | 15-40s |
| **Calibration Time** | 5-15s | 8-20s | 8-20s |
| **Memory Usage** | Low | Moderate | Moderate |
| **Accuracy** | 70-90% (MI) | 80-95% (P300) | 70-85% (Complex) |

All measurements on standard CPU (no GPU required).

## Technology Stack

**Python SDK:**
- **Core**: Python 3.10+, NumPy, JAX, NumPyro
- **Integration**: scikit-learn pipelines, MNE-Python
- **Models**: NimbusLDA, NimbusGMM, NimbusSoftmax (Polya-Gamma VI)

**Julia SDK:**
- **Core**: Julia 1.9+
- **Inference Engine**: [RxInfer.jl](https://rxinfer.com/) - Reactive message passing
- **Models**: RxLDAModel, RxGMMModel, RxPolyaModel

**Common:**
- **Preprocessing**: MNE-Python, EEGLAB, BrainFlow
- **API**: TypeScript/Vercel serverless (Julia SDK authentication)

## What's Included

**Python SDK** (`nimbus-bci`):
- ‚úÖ sklearn-compatible classifiers: NimbusLDA, NimbusGMM, NimbusSoftmax
- ‚úÖ MNE-Python integration for EEG preprocessing
- ‚úÖ Streaming inference for real-time BCI
- ‚úÖ Online learning with `partial_fit()`
- ‚úÖ Comprehensive metrics and diagnostics

**Julia SDK** (`NimbusSDK.jl`):
- ‚úÖ RxInfer.jl-based models: RxLDAModel, RxGMMModel, RxPolyaModel
- ‚úÖ Pre-trained model distribution
- ‚úÖ Batch and streaming inference
- ‚úÖ Training and calibration
- ‚úÖ Quality assessment and ITR calculation

## Support

<CardGroup cols={2}>
  <Card
    title="Email Support"
    icon="mail"
    href="mailto:hello@nimbusbci.com"
  >
    **hello@nimbusbci.com** - Technical support and inquiries
  </Card>
  <Card
    title="Book a Demo"
    icon="calendar"
    href="https://nimbusbci.com"
  >
    See Nimbus in action with live demonstration
  </Card>
  <Card
    title="API Status"
    icon="circle-check"
    href="https://api.nimbusbci.com/api/health"
  >
    Check API availability and version
  </Card>
  <Card
    title="GitHub"
    icon="github"
    href="https://github.com/nimbusbci/NimbusSDK.jl"
  >
    NimbusSDK.jl source code, issues, and examples
  </Card>
</CardGroup>

## License

**Python SDK** (`nimbus-bci`): Proprietary license with free evaluation and academic tiers. See [Python SDK Installation](/python-sdk/installation) for details.

**Julia SDK** (`NimbusSDK.jl`): Commercial software with tiered licensing:
- **Free**: 10K monthly inferences, basic models
- **Research**: 50K monthly inferences, all features  
- **Commercial**: 500K monthly inferences, priority support
- **Enterprise**: Unlimited, custom models, on-premise deployment

Contact **hello@nimbusbci.com** for licensing information.

---

**Built with ‚ù§Ô∏è for the neurotechnology community**

Nimbus BCI Engine - Bringing Bayesian inference to Brain-Computer Interfaces
