---
title: "Nimbus BCI Engine"
description: "Bayesian inference for Brain-Computer Interfaces using RxInfer.jl reactive message passing"
icon: "brain"
---

_Production-ready Bayesian BCI inference with RxLDA and RxGMM models_

NimbusSDK.jl provides fast, probabilistic inference for Brain-Computer Interface applications. Built on **RxInfer.jl**, the SDK delivers sub-20ms inference latency with full uncertainty quantification through **RxLDA** (Linear Discriminant Analysis) and **RxGMM** (Gaussian Mixture Model) implementations.

## Why Nimbus BCI

Brain-Computer Interfaces face unique challenges: noisy neural signals, inherent uncertainty, real-time requirements, and the need for explainability in medical applications.

**Current BCI Challenges:**
- **High Latency**: Standard processing takes 200ms+ for trial classification
- **No Uncertainty Quantification**: Deterministic outputs without confidence measures
- **Limited Adaptability**: Cannot handle changing brain states or signal quality
- **Black Box Models**: Deep learning lacks explainability for FDA approval

**Nimbus Solution:**
- ‚úÖ **Fast Inference**: 10-20ms per trial with Bayesian models
- ‚úÖ **Uncertainty Quantification**: Full posterior distributions, not just point estimates
- ‚úÖ **Training & Calibration**: Subject-specific personalization in minutes
- ‚úÖ **Explainable**: White-box probabilistic models for medical compliance
- ‚úÖ **Production-Ready**: Batch and streaming modes, quality assessment, performance tracking

<Card
  title="Get started with Nimbus"
  icon="rocket"
  href="/quickstart"
  horizontal
>
  Build your first BCI application in 10 minutes with Julia and NimbusSDK.jl
</Card>

## Core Features

<CardGroup cols={2}>
  <Card
    title="Fast Bayesian Inference"
    icon="bolt"
    href="/core-concepts/probabilistic-ai"
  >
    RxLDA and RxGMM models with 10-20ms inference latency using RxInfer.jl reactive message passing
  </Card>
  <Card
    title="Training & Calibration"
    icon="graduation-cap"
    href="/examples/advanced-applications"
  >
    Train custom models on your data or calibrate pre-trained models with 10-20 trials per subject
  </Card>
  <Card
    title="Real-time Streaming"
    icon="wave-square"
    href="/inference-configuration/streaming-inference"
  >
    Process EEG chunks as they arrive with chunk-by-chunk inference and weighted aggregation
  </Card>
  <Card
    title="Uncertainty Quantification"
    icon="shield"
    href="/core-concepts/uncertainty-handling"
  >
    Full posterior distributions with confidence scores for quality assessment and rejection
  </Card>
</CardGroup>

## Implemented Models

NimbusSDK.jl currently provides two production-ready Bayesian models:

<CardGroup cols={2}>
  <Card
    title="RxLDA"
    icon="brain"
    href="/models/rxlda"
  >
    **Linear Discriminant Analysis** with shared covariance. Fast (10-15ms), efficient, ideal for well-separated classes like motor imagery.
  </Card>
  <Card
    title="RxGMM"
    icon="brain"
    href="/models/rxgmm"
  >
    **Gaussian Mixture Model** with class-specific covariances. More flexible (15-25ms), better for overlapping distributions like P300.
  </Card>
</CardGroup>

## BCI Paradigms Supported

<CardGroup cols={3}>
  <Card
    title="Motor Imagery"
    icon="hand"
  >
    **2-4 class classification**
    - Left/right hand
    - Hands/feet/tongue
    - 70-90% accuracy
    - RxLDA recommended
  </Card>
  <Card
    title="P300"
    icon="eye"
  >
    **Binary classification**
    - Target/non-target
    - Speller applications
    - 80-95% accuracy
    - RxGMM recommended
  </Card>
  <Card
    title="SSVEP"
    icon="bolt"
  >
    **Multi-class frequency**
    - 2-6 target frequencies
    - High accuracy (85-98%)
    - Works with both models
  </Card>
</CardGroup>

## Quick Example

```julia
using NimbusSDK

# 1. Authenticate
NimbusSDK.authenticate("nbci_live_your_key")

# 2. Load pre-trained model
model = load_model(RxLDAModel, "motor_imagery_4class_v1")

# 3. Prepare preprocessed features (CSP, bandpower, etc.)
data = BCIData(csp_features, metadata, labels)

# 4. Run inference
results = predict_batch(model, data)

# 5. Analyze
println("Accuracy: $(sum(results.predictions .== labels) / length(labels))")
println("Mean confidence: $(mean(results.confidences))")
println("ITR: $(calculate_ITR(accuracy, 4, 4.0)) bits/minute")
```

## Use Cases

<CardGroup cols={2}>
  <Card
    title="Assistive Technologies"
    icon="wheelchair"
    href="/examples/industry-use-cases"
  >
    Wheelchair control, prosthetic limbs, communication devices with explainable, FDA-ready probabilistic models
  </Card>
  <Card
    title="Research Platforms"
    icon="microscope"
    href="/examples/basic-examples"
  >
    Academic research with training capabilities, subject-specific calibration, and comprehensive performance metrics
  </Card>
  <Card
    title="Neurofeedback"
    icon="brain"
    href="/inference-configuration/real-time-setup"
  >
    Real-time brain state monitoring with streaming inference and confidence-based quality control
  </Card>
  <Card
    title="Gaming & Wellness"
    icon="gamepad"
    href="/examples/advanced-applications"
  >
    Low-latency brain control for immersive experiences with adaptive difficulty based on confidence
  </Card>
</CardGroup>

## SDK Architecture

```
EEG Hardware ‚Üí Preprocessing ‚Üí NimbusSDK.jl ‚Üí Application
   (LSL/BrainFlow)  (MNE/EEGLAB)    (Local)      (Your Code)
```

**Key Design:**
- **Local Inference**: No API calls during inference - all processing on your machine
- **Privacy**: Your EEG data never leaves your computer
- **Speed**: No network latency, consistent &lt;20ms performance
- **Offline Capable**: Works without internet after initial setup

**API Role:**
- Authentication and licensing
- Pre-trained model distribution
- Optional analytics logging

## Getting Started

<Steps>
  <Step title="Install Julia SDK">
    ```julia
    using Pkg
    Pkg.add("NimbusSDK")
    ```
  </Step>
  <Step title="Get API Key">
    Contact **hello@nimbusbci.com** for your API key and license tier
  </Step>
  <Step title="Preprocess EEG">
    Use MNE-Python, EEGLAB, or your tool to extract features (CSP, bandpower, ERP)
  </Step>
  <Step title="Run Inference">
    Load model, process features, get predictions with confidence scores
  </Step>
</Steps>

## Documentation

<CardGroup cols={3}>
  <Card
    title="Quickstart"
    icon="rocket"
    href="/quickstart"
  >
    10-minute guide to your first BCI application
  </Card>
  <Card
    title="Julia SDK Reference"
    icon="code"
    href="/api-reference/julia-sdk"
  >
    Complete API documentation
  </Card>
  <Card
    title="Model Training"
    icon="graduation-cap"
    href="/examples/advanced-applications"
  >
    Train custom models on your data
  </Card>
  <Card
    title="Preprocessing Guide"
    icon="filter"
    href="/inference-configuration/preprocessing-requirements"
  >
    Required EEG preprocessing steps
  </Card>
  <Card
    title="Code Examples"
    icon="brackets-curly"
    href="/examples/code-samples"
  >
    Working Julia code examples
  </Card>
  <Card
    title="API Reference"
    icon="server"
    href="/api-reference/authentication"
  >
    Authentication and model registry
  </Card>
</CardGroup>

## Performance

| Metric | RxLDA | RxGMM |
|--------|-------|-------|
| **Inference Latency** | 10-15ms | 15-25ms |
| **Training Time** | 10-30s | 15-40s |
| **Calibration Time** | 5-15s | 8-20s |
| **Memory Usage** | Low | Moderate |
| **Accuracy** | 70-90% (MI) | 80-95% (P300) |

All measurements on standard CPU (no GPU required).

## Technology Stack

- **Core**: Julia 1.9+
- **Inference Engine**: [RxInfer.jl](https://rxinfer.ml/) - Reactive message passing for Bayesian inference
- **Models**: RxLDA (shared covariance), RxGMM (class-specific covariances)
- **Preprocessing**: MNE-Python, EEGLAB, BrainFlow (external)
- **API**: TypeScript/Vercel serverless (authentication, model registry)

## Roadmap

**Currently Implemented:**
- ‚úÖ RxLDA and RxGMM models
- ‚úÖ Batch and streaming inference
- ‚úÖ Training and calibration
- ‚úÖ Quality assessment and ITR calculation
- ‚úÖ API authentication and model registry

**Coming Soon:**
- üöß Autoregressive (AR) models for rhythm analysis
- üöß Hidden Markov Models (HMM) for state detection
- üöß Kalman filtering for signal processing
- üöß POMDP decision-making frameworks
- üöß Multi-modal sensor fusion

## Support

<CardGroup cols={2}>
  <Card
    title="Email Support"
    icon="envelope"
    href="mailto:hello@nimbusbci.com"
  >
    **hello@nimbusbci.com** - Technical support and inquiries
  </Card>
  <Card
    title="Book a Demo"
    icon="calendar"
    href="https://nimbusbci.com"
  >
    See Nimbus in action with live demonstration
  </Card>
  <Card
    title="API Status"
    icon="circle-check"
    href="https://api.nimbusbci.com/api/health"
  >
    Check API availability and version
  </Card>
  <Card
    title="GitHub"
    icon="github"
    href="https://github.com/nimbusbci"
  >
    NimbusSDK.jl source code and examples
  </Card>
</CardGroup>

## License

NimbusSDK.jl is commercial software with tiered licensing:

- **Free**: 10K monthly inferences, basic models
- **Research**: 50K monthly inferences, all features  
- **Commercial**: 500K monthly inferences, priority support
- **Enterprise**: Unlimited, custom models, on-premise deployment

Contact **hello@nimbusbci.com** for licensing information.

---

**Built with ‚ù§Ô∏è for the neurotechnology community**

Nimbus BCI Engine - Bringing Bayesian inference to Brain-Computer Interfaces
