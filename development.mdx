---
title: 'Development'
description: 'Development workflow for building BCI applications with Nimbus (Python & Julia)'
icon: 'code'
---

# Development Guide

This guide covers the development workflow for building BCI applications with **Nimbus BCI** in both Python and Julia, from local setup to production deployment.

<Note>
**Choose Your SDK:**
- **Python SDK** (`nimbus-pysdk`): Ideal for sklearn integration, MNE-Python workflows, and rapid prototyping
- **Julia SDK** (`NimbusSDK.jl`): Optimal for research applications requiring RxInfer.jl and custom Bayesian models

Both SDKs provide the same core Bayesian classifiers with language-specific ergonomics.
</Note>

## Development Environment Setup

### Prerequisites

<Tabs>
  <Tab title="Python SDK">
<Info>
**Required:**
- **Python 3.9+** (3.10+ recommended)
- **pip** or **conda** for package management
- **Git** for version control
- **EEG Hardware** or sample data for testing

**Recommended:**
- **VSCode** with Python extension or **PyCharm**
- **Jupyter** for interactive development
- **MNE-Python** for EEG preprocessing
- **scikit-learn** for ML pipelines
</Info>
  </Tab>
  <Tab title="Julia SDK">
<Info>
**Required:**
- **Julia 1.9+** (1.10+ recommended for best performance)
- **Git** for version control
- **API Key** from [Nimbus BCI](mailto:hello@nimbusbci.com)
- **EEG Hardware** or sample data for testing

**Recommended:**
- **VSCode** with Julia extension
- **Jupyter** for interactive development
- **Preprocessing pipeline** (CSP, bandpower, ERP extraction)
</Info>
  </Tab>
</Tabs>

### Installation

<Tabs>
  <Tab title="Python SDK">
<Steps>
<Step title="Install Python">

Ensure Python 3.9+ is installed:

```bash
# Verify installation
python --version
# Expected: Python 3.9.0 (or later)
```

</Step>

<Step title="Create Virtual Environment">

Set up an isolated Python environment for your BCI project:

```bash
# Create project directory
mkdir my-bci-project
cd my-bci-project

# Create virtual environment
python -m venv venv

# Activate (Linux/Mac)
source venv/bin/activate

# Activate (Windows)
# venv\Scripts\activate
```

</Step>

<Step title="Install nimbus-pysdk">

Install from PyPI:

```bash
# Install nimbus-pysdk
pip install nimbus-pysdk

# Optional: Install with MNE-Python
pip install "nimbus-pysdk[mne]"

# Verify installation
python -c "import nimbus_pysdk; print('âœ“ nimbus-pysdk installed')"
```

</Step>

<Step title="Install Dependencies">

For complete BCI workflow:

```bash
# Data science stack
pip install numpy scipy scikit-learn matplotlib

# EEG preprocessing (optional)
pip install mne

# Create requirements.txt
pip freeze > requirements.txt
```

</Step>
</Steps>
  </Tab>
  <Tab title="Julia SDK">
<Steps>
<Step title="Install Julia">

Download and install Julia from [julialang.org](https://julialang.org/downloads/):

```bash
# Verify installation
julia --version
# Expected: julia version 1.10.0 (or later)
```

</Step>

<Step title="Create Project Environment">

Set up an isolated Julia environment for your BCI project:

```bash
# Create project directory
mkdir my-bci-project
cd my-bci-project

# Initialize Julia project
julia --project=. -e 'using Pkg; Pkg.instantiate()'
```

</Step>

<Step title="Install NimbusSDK">

Add NimbusSDK to your project:

```julia
# Start Julia REPL
julia --project=.

# Install NimbusSDK from Julia General Registry
using Pkg
Pkg.add("NimbusSDK")

# Verify installation
using NimbusSDK
println("âœ“ NimbusSDK installed successfully")
```

</Step>

<Step title="Configure API Access">

Set up your API credentials:

```julia
# In Julia
using NimbusSDK

# One-time setup (installs core and authenticates)
NimbusSDK.install_core("your-api-key-here")

# Verify installation
println("âœ“ Core installed successfully")
```

**Security Best Practice:**

Store API keys in environment variables:

```bash
# In your shell (.bashrc, .zshrc, etc.)
export NIMBUS_API_KEY="your-api-key-here"
```

```julia
# In Julia
api_key = ENV["NIMBUS_API_KEY"]
NimbusSDK.install_core(api_key)
```

</Step>
</Steps>
  </Tab>
</Tabs>

## Project Structure

<Tabs>
  <Tab title="Python SDK">
Organize your Python BCI project:

```
my-bci-project/
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ setup.py              # Package configuration (optional)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py  # Feature extraction
â”‚   â”œâ”€â”€ training.py       # Model training
â”‚   â”œâ”€â”€ inference.py      # Real-time inference
â”‚   â””â”€â”€ utils.py          # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw EEG recordings
â”‚   â”œâ”€â”€ processed/        # Preprocessed features
â”‚   â””â”€â”€ models/           # Trained models (pickled)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_training.py
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration
â”‚   â””â”€â”€ motor_imagery_demo.ipynb
â””â”€â”€ README.md
```
  </Tab>
  <Tab title="Julia SDK">
Organize your Julia BCI project:

```
my-bci-project/
â”œâ”€â”€ Project.toml          # Julia dependencies
â”œâ”€â”€ Manifest.toml         # Locked dependency versions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ MyBCIProject.jl   # Main module
â”‚   â”œâ”€â”€ preprocessing.jl   # Feature extraction
â”‚   â”œâ”€â”€ training.jl        # Model training
â”‚   â”œâ”€â”€ inference.jl       # Real-time inference
â”‚   â””â”€â”€ utils.jl           # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Raw EEG recordings
â”‚   â”œâ”€â”€ processed/         # Preprocessed features
â”‚   â””â”€â”€ models/            # Trained models
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ runtests.jl        # Test suite
â”‚   â””â”€â”€ test_inference.jl  # Inference tests
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ motor_imagery_demo.jl
â””â”€â”€ README.md
```
  </Tab>
</Tabs>

## Development Workflow

### 1. Data Preparation

#### Preprocessing Pipeline

<Tabs>
  <Tab title="Python">
```python
# src/preprocessing.py
import numpy as np
from scipy import signal
from sklearn.covariance import LedoitWolf

def extract_csp_features(eeg_data: np.ndarray, csp_filters: np.ndarray) -> np.ndarray:
    """
    Extract CSP features for motor imagery BCI.
    
    Args:
        eeg_data: EEG data [n_channels Ã— n_samples]
        csp_filters: CSP spatial filters [n_components Ã— n_channels]
    
    Returns:
        features: Log-variance features [n_components]
    """
    # Apply spatial filters
    spatial_filtered = csp_filters @ eeg_data
    
    # Compute log-variance features
    features = np.log(np.var(spatial_filtered, axis=1) + 1e-10)
    
    return features

def extract_erp_features(eeg_epoch: np.ndarray, time_windows: list) -> np.ndarray:
    """
    Extract ERP amplitude features for P300 BCI.
    
    Args:
        eeg_epoch: EEG epoch [n_channels Ã— n_samples]
        time_windows: List of (start_sample, end_sample) tuples
    
    Returns:
        features: Mean amplitude features
    """
    features = []
    
    for start_idx, end_idx in time_windows:
        window_data = eeg_epoch[:, start_idx:end_idx]
        # Mean amplitude in window for each channel
        features.extend(np.mean(window_data, axis=1))
    
    return np.array(features)

def bandpass_filter(data: np.ndarray, low_freq: float, high_freq: float, fs: float) -> np.ndarray:
    """
    Apply bandpass filter to EEG data.
    
    Args:
        data: EEG data [n_channels Ã— n_samples]
        low_freq: Low frequency cutoff (Hz)
        high_freq: High frequency cutoff (Hz)
        fs: Sampling frequency (Hz)
    
    Returns:
        filtered_data: Bandpass filtered EEG
    """
    # Design Butterworth bandpass filter
    nyq = fs / 2.0
    low = low_freq / nyq
    high = high_freq / nyq
    b, a = signal.butter(4, [low, high], btype='band')
    
    # Apply filter to each channel
    filtered = np.zeros_like(data)
    for ch in range(data.shape[0]):
        filtered[ch, :] = signal.filtfilt(b, a, data[ch, :])
    
    return filtered

def compute_csp_filters(X_class1: np.ndarray, X_class2: np.ndarray, n_components: int = 6) -> np.ndarray:
    """
    Compute CSP filters from two classes of EEG data.
    
    Args:
        X_class1: EEG trials for class 1 [n_trials Ã— n_channels Ã— n_samples]
        X_class2: EEG trials for class 2 [n_trials Ã— n_channels Ã— n_samples]
        n_components: Number of CSP components to return
    
    Returns:
        csp_filters: CSP spatial filters [n_components Ã— n_channels]
    """
    # Compute covariance matrices
    cov1 = LedoitWolf().fit(X_class1.reshape(X_class1.shape[0], -1)).covariance_
    cov2 = LedoitWolf().fit(X_class2.reshape(X_class2.shape[0], -1)).covariance_
    
    # Solve generalized eigenvalue problem
    eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(cov1 + cov2) @ cov1)
    
    # Sort by eigenvalue
    idx = np.argsort(eigenvalues)[::-1]
    eigenvectors = eigenvectors[:, idx]
    
    # Return top and bottom components
    n_half = n_components // 2
    csp_filters = np.vstack([eigenvectors[:, :n_half].T, eigenvectors[:, -n_half:].T])
    
    return csp_filters
```
  </Tab>
  <Tab title="Julia">
```julia
# src/preprocessing.jl
using DSP, LinearAlgebra, Statistics

"""
    extract_csp_features(eeg_data, csp_filters) -> features

Extract CSP features for motor imagery BCI.
"""
function extract_csp_features(eeg_data::Matrix{Float64}, csp_filters::Matrix{Float64})
    # eeg_data: [n_channels Ã— n_samples]
    # csp_filters: [n_components Ã— n_channels]
    
    # Apply spatial filters
    spatial_filtered = csp_filters * eeg_data
    
    # Compute log-variance features
    features = log.(var(spatial_filtered, dims=2) .+ 1e-10)
    
    return vec(features)
end

"""
    extract_erp_features(eeg_epoch, time_windows) -> features

Extract ERP amplitude features for P300 BCI.
"""
function extract_erp_features(eeg_epoch::Matrix{Float64}, time_windows::Vector)
    # eeg_epoch: [n_channels Ã— n_samples]
    # time_windows: [(start_sample, end_sample), ...]
    
    features = Float64[]
    
    for (start_idx, end_idx) in time_windows
        window_data = eeg_epoch[:, start_idx:end_idx]
        # Mean amplitude in window for each channel
        append!(features, mean(window_data, dims=2))
    end
    
    return features
end

"""
    bandpass_filter(data, low_freq, high_freq, fs) -> filtered_data

Apply bandpass filter to EEG data.
"""
function bandpass_filter(data::Matrix{Float64}, low_freq::Float64, high_freq::Float64, fs::Float64)
    # Design Butterworth bandpass filter
    responsetype = Bandpass(low_freq, high_freq; fs=fs)
    designmethod = Butterworth(4)  # 4th order
    
    # Apply filter to each channel
    filtered = similar(data)
    for ch in 1:size(data, 1)
        filtered[ch, :] = filtfilt(digitalfilter(responsetype, designmethod), data[ch, :])
    end
    
    return filtered
end
```
  </Tab>
</Tabs>

### 2. Model Training

#### Training Workflow

<Tabs>
  <Tab title="Python">
```python
# src/training.py
from nimbus_pysdk import NimbusLDA
import numpy as np
import pickle
from datetime import date
from sklearn.model_selection import train_test_split

def train_motor_imagery_model(data_file: str):
    """
    Complete training workflow for motor imagery BCI.
    
    Args:
        data_file: Path to preprocessed feature file
    
    Returns:
        trained_model: Trained NimbusLDA classifier
    """
    print("="*60)
    print("Motor Imagery Model Training")
    print("="*60)
    
    # 1. Load and preprocess data
    print("\n1. Loading data...")
    features, labels = load_features(data_file)
    # features: (n_trials, n_features)
    # labels: (n_trials,)
    
    # 2. Validate data
    print("2. Validating data...")
    check_data_quality(features, labels)
    
    # 3. Split into train/test
    print("3. Splitting train/test...")
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    # 4. Train model
    print("4. Training NimbusLDA model...")
    clf = NimbusLDA(mu_scale=3.0)
    clf.fit(X_train, y_train)
    
    # 5. Evaluate
    print("\n5. Evaluating on test set...")
    predictions = clf.predict(X_test)
    probabilities = clf.predict_proba(X_test)
    
    accuracy = np.mean(predictions == y_test)
    mean_conf = np.mean(np.max(probabilities, axis=1))
    
    print("\n" + "="*60)
    print("Training Results")
    print("="*60)
    print(f"Test Accuracy: {accuracy * 100:.1f}%")
    print(f"Mean Confidence: {mean_conf:.3f}")
    
    # 6. Save model
    save_path = f"data/models/motor_imagery_{date.today()}.pkl"
    with open(save_path, 'wb') as f:
        pickle.dump(clf, f)
    print(f"\nâœ“ Model saved to: {save_path}")
    
    return clf

def check_data_quality(features: np.ndarray, labels: np.ndarray):
    """Validate training data quality"""
    # Check for NaN/Inf
    if np.any(np.isnan(features)) or np.any(np.isinf(features)):
        raise ValueError("Features contain NaN or Inf values")
    
    # Check shapes
    n_trials, n_features = features.shape
    assert len(labels) == n_trials, "Labels must match number of trials"
    
    # Check label distribution
    n_classes = len(np.unique(labels))
    print(f"   {n_trials} trials, {n_features} features, {n_classes} classes")
    print(f"   Feature range: [{features.min():.3f}, {features.max():.3f}]")
```
  </Tab>
  <Tab title="Julia SDK">
```julia
# src/training.jl
using NimbusSDK
using Statistics

"""
    train_motor_imagery_model(data_file::String) -> trained_model

Complete training workflow for motor imagery BCI.
"""
function train_motor_imagery_model(data_file::String)
    println("="^60)
    println("Motor Imagery Model Training")
    println("="^60)
    
    # 1. Load and preprocess data
    println("\n1. Loading data...")
    raw_data = load_eeg_data(data_file)
    
    # 2. Extract features (CSP)
    println("2. Extracting CSP features...")
    features, labels = extract_mi_features(raw_data)
    # features: [n_features Ã— n_samples Ã— n_trials]
    # labels: [n_trials]
    
    # 3. Create BCIData
    metadata = BCIMetadata(
        sampling_rate = 250.0,
        paradigm = :motor_imagery,
        feature_type = :csp,
        n_features = size(features, 1),
        n_classes = length(unique(labels)),
        chunk_size = nothing  # Batch mode
    )
    
    training_data = BCIData(features, metadata, labels)
    
    # 4. Validate data
    println("3. Validating data...")
    report = diagnose_preprocessing(training_data)
    println("   Quality score: $(round(report.quality_score * 100, digits=1))%")
    
    if report.quality_score < 0.6
        @warn "Low quality score - check preprocessing" score=report.quality_score
    end
    
    # 5. Split into train/test
    println("4. Splitting train/test...")
    train_data, test_data = split_data(training_data, test_ratio=0.2)
    
    # 6. Train model
    println("5. Training RxLDA model...")
    trained_model = train_model(
        RxLDAModel,
        train_data;
        iterations = 50,
        showprogress = true,
        name = "my_motor_imagery_model",
        description = "Trained on $(size(features, 3)) trials"
    )
    
    # 7. Evaluate
    println("\n6. Evaluating on test set...")
    test_results = predict_batch(trained_model, test_data)
    
    accuracy = sum(test_results.predictions .== test_data.labels) / length(test_results.predictions)
    mean_conf = mean(test_results.confidences)
    
    println("\n" * "="^60)
    println("Training Results")
    println("="^60)
    println("Test Accuracy: $(round(accuracy * 100, digits=1))%")
    println("Mean Confidence: $(round(mean_conf, digits=3))")
    
    # 8. Save model
    save_path = "data/models/motor_imagery_$(today()).jld2"
    save_model(trained_model, save_path)
    println("\nâœ“ Model saved to: $save_path")
    
    return trained_model
end

"""
    split_data(data::BCIData, test_ratio::Float64) -> (train, test)

Split BCIData into training and test sets.
"""
function split_data(data::BCIData, test_ratio::Float64=0.2)
    n_trials = size(data.features, 3)
    n_test = Int(floor(n_trials * test_ratio))
    n_train = n_trials - n_test
    
    # Random shuffle
    indices = randperm(n_trials)
    train_idx = indices[1:n_train]
    test_idx = indices[n_train+1:end]
    
    # Split features and labels
    train_features = data.features[:, :, train_idx]
    test_features = data.features[:, :, test_idx]
    
    train_labels = isnothing(data.labels) ? nothing : data.labels[train_idx]
    test_labels = isnothing(data.labels) ? nothing : data.labels[test_idx]
    
    train_data = BCIData(train_features, data.metadata, train_labels)
    test_data = BCIData(test_features, data.metadata, test_labels)
    
    return train_data, test_data
end
```
  </Tab>
</Tabs>

### 3. Real-Time Inference

#### Streaming Application

<Tabs>
  <Tab title="Python">
```python
# src/inference.py
from nimbus_pysdk import NimbusLDA, StreamingSession
from nimbus_pysdk.data import BCIMetadata
import numpy as np
import pickle
import time

def run_realtime_bci(model_path: str, duration_seconds: int = 60):
    """
    Run real-time BCI application.
    
    Args:
        model_path: Path to trained model file (.pkl)
        duration_seconds: Duration to run in seconds
    """
    print("="*60)
    print("Real-Time BCI Application")
    print("="*60)
    
    # 1. Load model
    print("\nLoading model...")
    with open(model_path, 'rb') as f:
        clf = pickle.load(f)
    print(f"âœ“ Model loaded: {model_path}")
    
    # 2. Configure streaming
    metadata = BCIMetadata(
        sampling_rate=250.0,
        paradigm="motor_imagery",
        feature_type="csp",
        n_features=16,
        n_classes=4,
        chunk_size=250  # 1-second chunks
    )
    
    # 3. Initialize streaming session
    print("Initializing streaming session...")
    session = StreamingSession(clf.model_, metadata)
    print("âœ“ Session initialized")
    
    # 4. Real-time loop
    print("\n" + "="*60)
    print(f"Starting real-time processing ({duration_seconds}s)")
    print("="*60)
    
    chunk_count = 0
    start_time = time.time()
    latencies = []
    confidences = []
    
    while (time.time() - start_time) < duration_seconds:
        # Acquire EEG chunk (replace with your hardware interface)
        raw_chunk = acquire_eeg_chunk()  # Your hardware interface
        
        # Extract features
        feature_chunk = extract_csp_features(raw_chunk)  # (16, 250)
        
        # Time inference
        t_start = time.perf_counter()
        result = session.process_chunk(feature_chunk)
        latency_ms = (time.perf_counter() - t_start) * 1000
        
        chunk_count += 1
        latencies.append(latency_ms)
        confidences.append(result.confidence)
        
        # Execute BCI command
        if result.confidence > 0.75:
            execute_bci_command(result.prediction)
        
        # Report every 10 chunks
        if chunk_count % 10 == 0:
            recent_lat = latencies[-10:]
            recent_conf = confidences[-10:]
            print(f"\nChunk {chunk_count}:")
            print(f"  Mean latency: {np.mean(recent_lat):.1f} ms")
            print(f"  Mean confidence: {np.mean(recent_conf):.3f}")
        
        session.reset()
    
    # 5. Summary
    print("\n" + "="*60)
    print("Session Complete")
    print("="*60)
    print(f"Total chunks: {chunk_count}")
    print(f"Mean latency: {np.mean(latencies):.1f} ms")
    print(f"Mean confidence: {np.mean(confidences):.3f}")

def execute_bci_command(prediction: int):
    """Execute BCI command based on prediction"""
    commands = ["Left", "Right", "Forward", "Stop"]
    print(f"â†’ Command: {commands[prediction]}")
    
    # Your application logic here
    # e.g., control wheelchair, game, cursor, etc.
```
  </Tab>
  <Tab title="Julia SDK">
```julia
# src/inference.jl
using NimbusSDK
using Statistics

"""
    run_realtime_bci(model_path::String; duration_seconds::Int=60)

Run real-time BCI application.
"""
function run_realtime_bci(model_path::String; duration_seconds::Int=60)
    println("="^60)
    println("Real-Time BCI Application")
    println("="^60)
    
    # 1. Authenticate
    NimbusSDK.install_core(ENV["NIMBUS_API_KEY"])
    
    # 2. Load model
    println("\nLoading model...")
    model = load_model(RxLDAModel, model_path)
    println("âœ“ Model loaded: $(model.metadata.name)")
    
    # 3. Configure streaming
    metadata = BCIMetadata(
        sampling_rate = 250.0,
        paradigm = :motor_imagery,
        feature_type = :csp,
        n_features = 16,
        n_classes = 4,
        chunk_size = 250  # 1-second chunks
    )
    
    # 4. Initialize session
    println("Initializing streaming session...")
    session = init_streaming(model, metadata)
    println("âœ“ Session initialized")
    
    # 5. Warmup
    println("\nWarmup (JIT compilation)...")
    dummy_chunk = randn(16, 250)
    for _ in 1:10
        process_chunk(session, dummy_chunk)
    end
    println("âœ“ Warmup complete")
    
    # 6. Real-time loop
    println("\n" * "="^60)
    println("Starting real-time processing ($(duration_seconds)s)")
    println("="^60)
    
    chunk_count = 0
    start_time = time()
    latencies = Float64[]
    confidences = Float64[]
    
    while (time() - start_time) < duration_seconds
        # Acquire EEG chunk (replace with your acquisition code)
        raw_chunk = acquire_eeg_chunk()  # Your hardware interface
        
        # Extract features
        feature_chunk = extract_csp_features(raw_chunk, model.csp_filters)
        
        # Time inference
        t_start = time()
        result = process_chunk(session, feature_chunk)
        latency_ms = (time() - t_start) * 1000
        
        chunk_count += 1
        push!(latencies, latency_ms)
        push!(confidences, result.confidence)
        
        # Execute BCI command
        if result.confidence > 0.75
            execute_bci_command(result.prediction)
        end
        
        # Report every 10 chunks
        if chunk_count % 10 == 0
            println("\nChunk $chunk_count:")
            println("  Mean latency: $(round(mean(latencies[max(1, end-9):end]), digits=1)) ms")
            println("  Mean confidence: $(round(mean(confidences[max(1, end-9):end]), digits=3))")
        end
    end
    
    # 7. Summary
    println("\n" * "="^60)
    println("Session Complete")
    println("="^60)
    println("Total chunks: $chunk_count")
    println("Mean latency: $(round(mean(latencies), digits=1)) ms")
    println("Mean confidence: $(round(mean(confidences), digits=3))")
end

"""
    execute_bci_command(prediction::Int)

Execute BCI command based on prediction.
"""
function execute_bci_command(prediction::Int)
    commands = ["Left", "Right", "Forward", "Stop"]
    println("â†’ Command: $(commands[prediction])")
    
    # Your application logic here
    # e.g., control wheelchair, game, cursor, etc.
end
```
  </Tab>
</Tabs>

### 4. Testing

#### Test Suite

<Tabs>
  <Tab title="Python">
```python
# tests/test_training.py
import pytest
import numpy as np
from nimbus_pysdk import NimbusLDA, NimbusGMM
from nimbus_pysdk.data import BCIData, BCIMetadata

def test_model_training():
    """Test basic model training"""
    # Create synthetic data
    X_train = np.random.randn(50, 8)
    y_train = np.random.randint(0, 2, 50)
    
    # Train model
    clf = NimbusLDA()
    clf.fit(X_train, y_train)
    
    # Verify model properties
    assert clf.n_features_in_ == 8
    assert len(clf.classes_) == 2

def test_batch_inference():
    """Test batch prediction"""
    # Train model
    clf = NimbusLDA()
    X_train = np.random.randn(30, 8)
    y_train = np.random.randint(0, 2, 30)
    clf.fit(X_train, y_train)
    
    # Test prediction
    X_test = np.random.randn(20, 8)
    predictions = clf.predict(X_test)
    probabilities = clf.predict_proba(X_test)
    
    assert len(predictions) == 20
    assert probabilities.shape == (20, 2)
    assert np.all((probabilities >= 0) & (probabilities <= 1))
    assert np.allclose(probabilities.sum(axis=1), 1.0)

def test_streaming_inference():
    """Test streaming inference"""
    # Train model
    clf = NimbusLDA()
    X_train = np.random.randn(30, 8)
    y_train = np.random.randint(0, 2, 30)
    clf.fit(X_train, y_train)
    
    # Create streaming session
    from nimbus_pysdk import StreamingSession
    from nimbus_pysdk.data import BCIMetadata
    
    metadata = BCIMetadata(
        sampling_rate=250.0,
        n_features=8,
        n_classes=2,
        chunk_size=100
    )
    
    session = StreamingSession(clf.model_, metadata)
    
    # Process chunk
    chunk = np.random.randn(8, 100)
    result = session.process_chunk(chunk)
    
    assert result.prediction in [0, 1]
    assert 0 <= result.confidence <= 1

def test_cross_validation():
    """Test cross-validation compatibility"""
    from sklearn.model_selection import cross_val_score
    
    clf = NimbusLDA()
    X = np.random.randn(100, 8)
    y = np.random.randint(0, 2, 100)
    
    # Run cross-validation
    scores = cross_val_score(clf, X, y, cv=5)
    
    assert len(scores) == 5
    assert all(0 <= score <= 1 for score in scores)

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```
  </Tab>
  <Tab title="Julia SDK">
```julia
# test/runtests.jl
using Test
using NimbusSDK

@testset "NimbusSDK Tests" begin
    
    @testset "Data Validation" begin
        # Test BCIData creation
        features = randn(16, 250, 10)
        metadata = BCIMetadata(
            sampling_rate = 250.0,
            n_features = 16,
            n_classes = 4
        )
        labels = rand(1:4, 10)
        
        data = BCIData(features, metadata, labels)
        @test size(data.features) == (16, 250, 10)
        @test length(data.labels) == 10
    end
    
    @testset "Model Training" begin
        # Test RxLDA training
        features = randn(8, 100, 50)
        labels = rand(1:2, 50)
        metadata = BCIMetadata(
            sampling_rate = 250.0,
            n_features = 8,
            n_classes = 2
        )
        
        data = BCIData(features, metadata, labels)
        model = train_model(RxLDAModel, data; iterations=10)
        
        @test model isa RxLDAModel
        @test get_n_features(model) == 8
        @test get_n_classes(model) == 2
    end
    
    @testset "Batch Inference" begin
        # Test prediction
        features = randn(8, 100, 20)
        metadata = BCIMetadata(
            sampling_rate = 250.0,
            n_features = 8,
            n_classes = 2
        )
        
        data = BCIData(features, metadata)
        model = train_model(RxLDAModel, BCIData(randn(8, 100, 30), metadata, rand(1:2, 30)); iterations=10)
        
        results = predict_batch(model, data)
        
        @test length(results.predictions) == 20
        @test length(results.confidences) == 20
        @test all(0 .<= results.confidences .<= 1)
    end
    
    @testset "Streaming Inference" begin
        # Test streaming
        model = train_model(RxLDAModel, BCIData(randn(8, 100, 30), metadata, rand(1:2, 30)); iterations=10)
        
        metadata = BCIMetadata(
            sampling_rate = 250.0,
            n_features = 8,
            n_classes = 2,
            chunk_size = 100
        )
        
        session = init_streaming(model, metadata)
        
        chunk = randn(8, 100)
        result = process_chunk(session, chunk)
        
        @test result.prediction in 1:2
        @test 0 <= result.confidence <= 1
    end
end

println("\nâœ“ All tests passed!")
```
  </Tab>
</Tabs>

## Best Practices

### Code Organization

<Card title="Module Structure" icon="folder">
  ```julia
  # src/MyBCIProject.jl
  module MyBCIProject

  using NimbusSDK
  using Statistics

  include("preprocessing.jl")
  include("training.jl")
  include("inference.jl")
  include("utils.jl")

  export train_motor_imagery_model,
         run_realtime_bci,
         extract_csp_features

  end  # module
  ```
</Card>

### Error Handling

```julia
function safe_inference(model, data::BCIData)
    try
        results = predict_batch(model, data)
        return results
    catch e
        if e isa DimensionMismatch
            @error "Feature dimension mismatch" expected=get_n_features(model) actual=size(data.features, 1)
        elseif e isa ArgumentError
            @error "Invalid argument" exception=e
        else
            @error "Inference failed" exception=e
        end
        return nothing
    end
end
```

### Performance Monitoring

```julia
using Statistics

struct PerformanceMonitor
    latencies::Vector{Float64}
    confidences::Vector{Float64}
end

PerformanceMonitor() = PerformanceMonitor(Float64[], Float64[])

function record!(monitor::PerformanceMonitor, latency_ms::Float64, confidence::Float64)
    push!(monitor.latencies, latency_ms)
    push!(monitor.confidences, confidence)
end

function report(monitor::PerformanceMonitor)
    println("Performance Report:")
    println("  Mean latency: $(round(mean(monitor.latencies), digits=1)) ms")
    println("  95th percentile: $(round(quantile(monitor.latencies, 0.95), digits=1)) ms")
    println("  Mean confidence: $(round(mean(monitor.confidences), digits=3))")
end
```

## Debugging Tips

### Common Issues

<AccordionGroup>
  <Accordion title="Slow First Inference">
    **Cause**: Julia's JIT compilation
    
    **Solution**: Run warmup inferences
    ```julia
    # Warmup
    dummy_data = randn(16, 250, 1)
    for _ in 1:10
        predict_batch(model, BCIData(dummy_data, metadata))
    end
    # Now real inference will be fast
    ```
  </Accordion>
  
  <Accordion title="Dimension Mismatch">
    **Cause**: Feature count doesn't match model
    
    **Solution**: Verify dimensions
    ```julia
    println("Model expects: $(get_n_features(model)) features")
    println("Data has: $(size(data.features, 1)) features")
    ```
  </Accordion>
  
  <Accordion title="Low Confidence">
    **Cause**: Poor preprocessing or model calibration
    
    **Solution**: Run diagnostics
    ```julia
    report = diagnose_preprocessing(data)
    println("Quality: $(report.quality_score)")
    for warning in report.warnings
        println("  â€¢ $warning")
    end
    ```
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Python SDK" icon="python" href="/python-sdk/introduction">
    Python SDK overview and quickstart
  </Card>
  <Card title="Julia SDK Reference" icon="book" href="/api-reference/julia-sdk">
    Complete Julia API documentation
  </Card>
  <Card title="Code Examples" icon="code" href="/examples/code-samples">
    Working examples in both languages
  </Card>
  <Card title="Preprocessing" icon="radio" href="/development/preprocessing-integration">
    Integrate with MNE, EEGLAB, etc.
  </Card>
</CardGroup>

## Support

Need help?

- **Email**: hello@nimbusbci.com
- **Documentation**: Browse comprehensive guides
- **GitHub**: Report issues and contribute

Happy coding! ðŸš€ Build amazing BCI applications with NimbusSDK.
