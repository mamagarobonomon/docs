---
title: "Basic BCI Examples"
description: "Fundamental probabilistic models for brain-computer interface applications"
icon: "play"
---

# Basic BCI Examples

This section provides fundamental examples of probabilistic models commonly used in brain-computer interface applications. Each example demonstrates core concepts adapted from established probabilistic inference techniques, specifically tailored for neural signal processing and BCI control.

<Note>
For detailed implementations and advanced features of each model, see the dedicated pages in the **BCI Models** section.
</Note>

## Kalman Filtering for EEG Signal Processing

Kalman filtering is essential for tracking neural states and removing noise from EEG signals. This example demonstrates how to use Nimbus for real-time EEG preprocessing and state estimation.

### Problem Setup

EEG signals are inherently noisy and contain artifacts from eye movements, muscle activity, and environmental interference. We model the clean neural signal as a hidden state that evolves over time, observed through noisy EEG measurements.

```python
@model
def eeg_kalman_filter(eeg_observations, sampling_rate=250):
    """
    Kalman filter for EEG signal denoising and state tracking
    
    Args:
        eeg_observations: Raw EEG measurements [channels x time]
        sampling_rate: EEG sampling frequency in Hz
    """
    
    # System parameters
    dt = 1.0 / sampling_rate
    num_channels, num_samples = eeg_observations.shape
    
    # State transition model (neural signal dynamics)
    # Simple random walk with momentum for neural oscillations
    A = np.array([[1.0, dt], [0.0, 0.95]])  # [signal, velocity]
    
    # Process noise (neural variability)
    Q = np.array([[0.1, 0.0], [0.0, 0.05]])
    
    # Observation model (EEG measurement)
    H = np.array([1.0, 0.0])  # Observe signal directly
    
    # Measurement noise (electrode/amplifier noise)
    R = 2.5  # Typical EEG noise variance
    
    # Prior for initial state
    neural_state[0] ~ MultivariateNormal(
        mean=[0.0, 0.0], 
        covariance=[[10.0, 0.0], [0.0, 1.0]]
    )
    
    # State evolution and observations
    for t in range(1, num_samples):
        # Neural state dynamics
        neural_state[t] ~ MultivariateNormal(
            mean=A @ neural_state[t-1],
            covariance=Q
        )
        
        # EEG observations for each channel
        for ch in range(num_channels):
            eeg_observations[ch, t] ~ Normal(
                mean=H @ neural_state[t] * channel_weights[ch],
                variance=R
            )
```

### BCI Application: Motor Imagery Preprocessing

```python
# Real-time EEG preprocessing for motor imagery BCI
class EEGPreprocessor:
    def __init__(self, channels=['C3', 'C4', 'Cz'], sampling_rate=250):
        self.model = eeg_kalman_filter(sampling_rate=sampling_rate)
        self.channels = channels
        
    def process_window(self, eeg_window):
        """Process 1-second EEG window for motor imagery detection"""
        
        # Apply Kalman filtering
        result = self.model.infer(
            eeg_observations=eeg_window,
            target='neural_state'
        )
        
        # Extract clean neural signals
        clean_signals = result.mean[:, 0]  # Signal component
        confidence = 1.0 / result.variance[:, 0]  # Inverse variance
        
        return {
            'clean_eeg': clean_signals,
            'confidence': confidence,
            'artifacts_detected': confidence < 0.1
        }

# Usage example
preprocessor = EEGPreprocessor()

for eeg_window in real_time_stream():
    processed = preprocessor.process_window(eeg_window)
    
    if not processed['artifacts_detected']:
        # Feed to motor imagery classifier
        motor_intent = classify_motor_imagery(processed['clean_eeg'])
        send_control_command(motor_intent)
```

<Card title="Performance Metrics" icon="chart-bar">
  **Noise Reduction**: 15-25 dB improvement in SNR
  
  **Latency**: Sub-10ms processing time per sample
  
  **Artifact Detection**: 95%+ accuracy for eye blinks and muscle artifacts
</Card>

## Hidden Markov Models for Brain State Detection

Hidden Markov Models excel at detecting discrete brain states like attention levels, fatigue, and cognitive load from continuous neural signals.

### Problem Setup

We model brain states as discrete hidden variables that transition over time, generating observable patterns in EEG spectral features.

```python
@model
def brain_state_hmm(spectral_features, num_states=3):
    """
    HMM for detecting brain states from EEG spectral features
    
    Args:
        spectral_features: Power in frequency bands [time x bands]
        num_states: Number of discrete brain states
    """
    
    # State definitions: 0=Alert, 1=Relaxed, 2=Drowsy
    state_names = ['Alert', 'Relaxed', 'Drowsy']
    
    # Initial state probabilities
    initial_probs ~ Dirichlet(alpha=[1.0, 1.0, 1.0])
    
    # State transition probabilities
    for i in range(num_states):
        transition_probs[i] ~ Dirichlet(alpha=[2.0, 1.0, 1.0])
    
    # Emission parameters for each state
    for state in range(num_states):
        # Mean spectral power for each frequency band
        emission_means[state] ~ MultivariateNormal(
            mean=state_priors[state],
            covariance=np.eye(len(frequency_bands))
        )
        
        # Precision (inverse variance) for observations
        emission_precision[state] ~ Gamma(alpha=2.0, beta=1.0)
    
    # Initial state
    brain_state[0] ~ Categorical(probs=initial_probs)
    
    # State sequence and observations
    for t in range(1, len(spectral_features)):
        # State transition
        brain_state[t] ~ Categorical(
            probs=transition_probs[brain_state[t-1]]
        )
        
        # Spectral feature observations
        spectral_features[t] ~ MultivariateNormal(
            mean=emission_means[brain_state[t]],
            precision=emission_precision[brain_state[t]]
        )
```

### BCI Application: Attention Monitoring System

```python
class AttentionMonitor:
    def __init__(self, frequency_bands=['theta', 'alpha', 'beta']):
        self.model = brain_state_hmm(num_states=3)
        self.bands = frequency_bands
        self.state_names = ['Alert', 'Relaxed', 'Drowsy']
        
    def extract_spectral_features(self, eeg_data):
        """Extract power spectral density features"""
        
        features = []
        for band in self.bands:
            if band == 'theta':
                power = bandpower(eeg_data, 4, 8)
            elif band == 'alpha':
                power = bandpower(eeg_data, 8, 13)
            elif band == 'beta':
                power = bandpower(eeg_data, 13, 30)
            
            features.append(np.log(power))  # Log-transform for normality
        
        return np.array(features)
    
    def monitor_attention(self, eeg_stream, window_size=2.0):
        """Real-time attention state monitoring"""
        
        spectral_history = []
        
        for eeg_window in eeg_stream:
            # Extract spectral features
            features = self.extract_spectral_features(eeg_window)
            spectral_history.append(features)
            
            if len(spectral_history) >= 10:  # Minimum history for HMM
                # Infer current brain state
                result = self.model.infer(
                    spectral_features=np.array(spectral_history),
                    target='brain_state'
                )
                
                current_state = result.mode[-1]  # Most recent state
                confidence = result.probability[current_state]
                
                yield {
                    'state': self.state_names[current_state],
                    'confidence': confidence,
                    'alert_level': 1.0 - (current_state / 2.0)  # 1.0=Alert, 0.0=Drowsy
                }

# Usage for adaptive BCI interface
monitor = AttentionMonitor()

for attention_data in monitor.monitor_attention(eeg_stream):
    if attention_data['alert_level'] < 0.3:
        # User is drowsy - pause BCI or increase stimulation
        adjust_interface_difficulty(difficulty='easy')
    elif attention_data['alert_level'] > 0.8:
        # User is highly alert - can handle complex tasks
        adjust_interface_difficulty(difficulty='hard')
```

<Card title="Clinical Applications" icon="heartbeat">
  **Attention Disorders**: Monitor ADHD treatment effectiveness
  
  **Fatigue Detection**: Safety systems for drivers and operators
  
  **Cognitive Load**: Adaptive learning systems and rehabilitation
</Card>

## Autoregressive Models for EEG Rhythm Analysis

Autoregressive (AR) models are fundamental for analyzing EEG rhythms and detecting oscillatory patterns associated with different brain states and motor intentions.

### Problem Setup

EEG signals contain rhythmic oscillations (alpha, beta, mu rhythms) that can be modeled as autoregressive processes. Changes in AR parameters indicate shifts in neural activity patterns.

```python
@model
def eeg_ar_model(eeg_signal, ar_order=8, adaptive=True):
    """
    Autoregressive model for EEG rhythm analysis
    
    Args:
        eeg_signal: Single-channel EEG time series
        ar_order: Order of autoregressive model
        adaptive: Whether to use time-varying parameters
    """
    
    # AR coefficients (time-varying if adaptive)
    if adaptive:
        # Time-varying AR coefficients for non-stationary EEG
        ar_innovation_precision ~ Gamma(alpha=2.0, beta=1.0)
        
        for t in range(ar_order, len(eeg_signal)):
            if t == ar_order:
                # Initial AR coefficients
                ar_coeffs[t] ~ MultivariateNormal(
                    mean=np.zeros(ar_order),
                    precision=0.1 * np.eye(ar_order)
                )
            else:
                # Evolving AR coefficients
                ar_coeffs[t] ~ MultivariateNormal(
                    mean=ar_coeffs[t-1],
                    precision=ar_innovation_precision * np.eye(ar_order)
                )
    else:
        # Static AR coefficients
        ar_coeffs ~ MultivariateNormal(
            mean=np.zeros(ar_order),
            precision=0.1 * np.eye(ar_order)
        )
    
    # Observation noise precision
    noise_precision ~ Gamma(alpha=2.0, beta=1.0)
    
    # AR process
    for t in range(ar_order, len(eeg_signal)):
        # Predicted signal from AR model
        ar_prediction = sum([
            ar_coeffs[t][i] * eeg_signal[t-i-1] 
            for i in range(ar_order)
        ])
        
        # Observed EEG signal
        eeg_signal[t] ~ Normal(
            mean=ar_prediction,
            precision=noise_precision
        )
```

### BCI Application: Motor Imagery Rhythm Detection

```python
class MotorRhythmDetector:
    def __init__(self, channels=['C3', 'C4'], ar_order=8):
        self.model = eeg_ar_model(ar_order=ar_order, adaptive=True)
        self.channels = channels
        self.baseline_coeffs = {}
        
    def calibrate_baseline(self, rest_eeg_data):
        """Calibrate baseline AR parameters during rest"""
        
        for ch, channel in enumerate(self.channels):
            result = self.model.infer(
                eeg_signal=rest_eeg_data[ch],
                target='ar_coeffs'
            )
            
            self.baseline_coeffs[channel] = result.mean
    
    def detect_motor_imagery(self, eeg_window):
        """Detect motor imagery from AR parameter changes"""
        
        motor_scores = {}
        
        for ch, channel in enumerate(self.channels):
            # Estimate current AR parameters
            result = self.model.infer(
                eeg_signal=eeg_window[ch],
                target='ar_coeffs'
            )
            
            current_coeffs = result.mean
            baseline_coeffs = self.baseline_coeffs[channel]
            
            # Compute spectral power from AR coefficients
            current_psd = ar_to_psd(current_coeffs, sampling_rate=250)
            baseline_psd = ar_to_psd(baseline_coeffs, sampling_rate=250)
            
            # Motor imagery typically suppresses mu rhythm (8-13 Hz)
            mu_suppression = (
                baseline_psd[8:13].mean() - current_psd[8:13].mean()
            ) / baseline_psd[8:13].mean()
            
            motor_scores[channel] = mu_suppression
        
        # Lateralized motor imagery detection
        left_motor = motor_scores['C4']   # Contralateral suppression
        right_motor = motor_scores['C3']  # Contralateral suppression
        
        if left_motor > 0.2 and left_motor > right_motor + 0.1:
            return {'class': 'left_hand', 'confidence': left_motor}
        elif right_motor > 0.2 and right_motor > left_motor + 0.1:
            return {'class': 'right_hand', 'confidence': right_motor}
        else:
            return {'class': 'rest', 'confidence': 0.0}

# Real-time motor imagery BCI
detector = MotorRhythmDetector()

# Calibration phase
detector.calibrate_baseline(rest_eeg_data)

# Online detection
for eeg_window in motor_imagery_stream():
    prediction = detector.detect_motor_imagery(eeg_window)
    
    if prediction['confidence'] > 0.3:
        execute_motor_command(prediction['class'])
```

<Card title="Rhythm Analysis Features" icon="signal">
  **Mu Rhythm (8-13 Hz)**: Motor cortex activity and imagery
  
  **Alpha Rhythm (8-13 Hz)**: Attention and relaxation states
  
  **Beta Rhythm (13-30 Hz)**: Active concentration and motor planning
</Card>

## Detailed Model Pages

<CardGroup cols={2}>
  <Card title="Kalman EEG Filtering" icon="wave-square" href="/models/kalman-eeg-filtering">
    Complete implementation of EEG preprocessing with Kalman filters
  </Card>
  <Card title="HMM Brain States" icon="brain" href="/models/hmm-brain-states">
    Hidden Markov Models for attention and cognitive state detection
  </Card>
  <Card title="AR Motor Rhythms" icon="wave-square" href="/models/ar-motor-rhythms">
    Autoregressive models for motor imagery and rhythm analysis
  </Card>
  <Card title="Multi-Modal Fusion" icon="layers" href="/models/sensor-fusion">
    Sensor fusion for robust multi-modal BCI systems
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Advanced Examples" icon="cog" href="/examples/advanced-applications">
    Explore more sophisticated BCI models and techniques
  </Card>
  <Card title="Model Specification" icon="code" href="/model-specification/bci-examples">
    Learn how to build custom BCI models from scratch
  </Card>
  <Card title="Real-time Deployment" icon="play" href="/inference-configuration/streaming-inference">
    Deploy these models for live BCI applications
  </Card>
  <Card title="Performance Optimization" icon="chart-bar" href="/core-concepts/real-time-processing">
    Optimize models for sub-20ms inference latency
  </Card>
</CardGroup>

## Performance Summary

| Model Type | Typical Accuracy | Latency | Use Case |
|------------|------------------|---------|----------|
| Kalman Filter | 15-25 dB SNR improvement | <10ms | Signal preprocessing |
| HMM Brain States | 85-95% state detection | <50ms | Attention monitoring |
| AR Motor Rhythms | 75-90% motor classification | <30ms | Motor imagery BCI |

These fundamental models form the building blocks for more complex BCI applications. Each can be combined and extended to create sophisticated, real-time brain-computer interfaces tailored to specific applications and user needs.
