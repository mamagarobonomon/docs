---
title: "Bayesian GMM (RxGMM)"
description: "Bayesian Gaussian Mixture Model with class-specific covariances using RxInfer.jl"
icon: "brain"
---

# Bayesian GMM (RxGMM) - Bayesian Gaussian Mixture Model

**API Name**: `RxGMMModel`  
**Mathematical Model**: Heteroscedastic Gaussian Classifier (HGC)

Bayesian GMM (also known as RxGMM in the codebase) is a Bayesian classification model with **class-specific covariance matrices**, making it more flexible than Bayesian LDA for modeling complex class distributions. Implemented using RxInfer.jl's reactive message passing.

<Note>
**Bayesian GMM (RxGMM) is currently implemented** in NimbusSDK.jl and ready for production BCI applications. GMM is widely recognized in machine learning, and "Bayesian" signals our uncertainty quantification and posterior probability outputs.
</Note>

## Overview

Bayesian GMM extends beyond traditional Gaussian classifiers by allowing each class to have its own covariance structure:

- ✅ **Class-specific covariances** (unlike RxLDA's shared covariance)
- ✅ **More flexible modeling** of heterogeneous distributions
- ✅ **Posterior probability distributions** with uncertainty quantification
- ✅ **Fast inference** (~15-25ms per trial)
- ✅ **Training and calibration** support
- ✅ **Batch and streaming** inference modes

### When to Use Bayesian GMM

**Bayesian GMM is ideal for:**
- Complex, overlapping class distributions
- Classes with significantly different variances
- P300 detection (target/non-target with different spreads)
- When Bayesian LDA accuracy is unsatisfactory
- When you need maximum flexibility

**Use [Bayesian LDA](/models/rxlda) instead if:**
- Classes are well-separated and have similar spreads
- Speed is critical (Bayesian LDA is faster)
- Training data is limited (Bayesian LDA needs less data)
- Memory is constrained (Bayesian LDA uses less memory)

## Model Architecture

### Mathematical Foundation (Heteroscedastic Gaussian Classifier)

Bayesian GMM implements a Heteroscedastic Gaussian Classifier (HGC), which models class-conditional distributions with **class-specific precision matrices**:

```
p(x | y=k) = N(μ_k, W_k^-1)
```

Where:
- `μ_k` = mean vector for class k
- `W_k` = **class-specific** precision matrix (different for each class)
- Allows different covariance structures per class

**Key Difference from Bayesian LDA**: Each class can have its own covariance structure, making the model more flexible but also more parameter-heavy.

### Hyperparameters (v0.2.0+)

Bayesian GMM supports configurable hyperparameters for optimal performance tuning:

**Available Hyperparameters:**

| Parameter | Type | Default | Range | Description |
|-----------|------|---------|-------|-------------|
| `dof_offset` | Int | 2 | [1, 5] | Degrees of freedom offset for Wishart priors |
| `mean_prior_precision` | Float64 | 0.01 | [0.001, 0.1] | Prior precision for class means |
| `predictive_mean_prior` | Float64 | 1e6 | [1e4, 1e8] | Mean prior strength during inference |
| `predictive_dof_offset` | Int | 2 | [1, 5] | DOF offset for inference (should match `dof_offset`) |

**Parameter Effects:**

- **dof_offset**: Controls regularization strength
  - Lower values (1) → More data-driven, less regularization
  - Higher values (3-5) → More regularization, more conservative
  
- **mean_prior_precision**: Controls prior strength on class means
  - Lower values (0.001) → Weaker prior, trusts data more
  - Higher values (0.05-0.1) → Stronger prior, more regularization

- **predictive_mean_prior**: Very high values (1e6) indicate strong trust in learned parameters during inference

- **predictive_dof_offset**: Should typically match `dof_offset` for consistency

<Note>
**New in v0.2.0**: Hyperparameter configuration allows you to optimize model behavior for your specific dataset characteristics (SNR, trial count, data quality).
</Note>

### Model Structure

```julia
struct RxGMMModel <: BCIModel
    means::Vector{Vector{Float64}}       # Class means [μ₁, μ₂, ..., μₖ]
    precisions::Vector                   # Class-specific precisions [W₁, W₂, ..., Wₖ]
    metadata::ModelMetadata              # Model info
    dof_offset::Int                      # Degrees of freedom offset
    mean_prior_precision::Float64        # Mean prior precision
    predictive_mean_prior::Float64       # Predictive mean prior
    predictive_dof_offset::Int           # Predictive DOF offset
end
```

### RxInfer Implementation

**Learning Phase:**
```julia
@model function RxGMM_learning_model(y, labels, n_features, n_classes)
    # Priors on class means
    for k in 1:n_classes
        m[k] ~ MvNormal(0, 10*I)
    end
    
    # Priors on class-specific precisions
    for k in 1:n_classes
        W[k] ~ Wishart(n_features + 5, I)  # Each class has its own W
    end
    
    # Likelihood
    for i in eachindex(y)
        k = labels[i]
        y[i] ~ MvNormal(m[k], inv(W[k]))  # Class-specific precision
    end
end
```

## Usage

### 1. Load Pre-trained Model

```julia
using NimbusSDK

# Authenticate
NimbusSDK.install_core("nbci_live_your_key")

# Load from Nimbus model zoo
model = load_model(RxGMMModel, "p300_gmm_v1")

println("Model loaded:")
println("  Features: $(get_n_features(model))")
println("  Classes: $(get_n_classes(model))")
println("  Paradigm: $(get_paradigm(model))")
```

### 2. Train Custom Model

```julia
using NimbusSDK

# Prepare training data with labels
train_features = erp_features  # (8 × 200 × 150) - preprocessed P300 features
train_labels = [1, 2, 1, 2, ...]  # 150 labels (1=target, 2=non-target)

train_data = BCIData(
    train_features,
    BCIMetadata(
        sampling_rate = 250.0,
        paradigm = :p300,
        feature_type = :erp,
        n_features = 8,
        n_classes = 2,
        chunk_size = nothing
    ),
    train_labels  # Required for training!
)

# Train RxGMM model with default hyperparameters
model = train_model(
    RxGMMModel,
    train_data;
    iterations = 50,        # Inference iterations
    showprogress = true,    # Show progress bar
    name = "my_p300_gmm",
    description = "P300 binary classifier with RxGMM"
)

# Or train with custom hyperparameters (v0.2.0+)
model = train_model(
    RxGMMModel,
    train_data;
    iterations = 50,
    showprogress = true,
    name = "my_p300_gmm_tuned",
    description = "P300 classifier with tuned hyperparameters",
    dof_offset = 2,                    # DOF offset (default: 2)
    mean_prior_precision = 0.01,       # Prior precision (default: 0.01)
    predictive_mean_prior = 1e6,       # Inference prior (default: 1e6)
    predictive_dof_offset = 2          # Inference DOF (default: 2)
)

# Save for later use
save_model(model, "my_p300_gmm.jld2")
```

**Training Parameters:**
- `iterations`: Number of variational inference iterations (default: 50)
  - More iterations = better convergence, typical range: 50-100
- `showprogress`: Display progress bar during training
- `name`: Model identifier
- `description`: Model description
- `dof_offset`: Degrees of freedom offset (default: 2, range: [1, 5]) - **v0.2.0+**
- `mean_prior_precision`: Prior precision for means (default: 0.01, range: [0.001, 0.1]) - **v0.2.0+**
- `predictive_mean_prior`: Inference prior strength (default: 1e6, range: [1e4, 1e8]) - **v0.2.0+**
- `predictive_dof_offset`: Inference DOF offset (default: 2, range: [1, 5]) - **v0.2.0+**

### 3. Subject-Specific Calibration

```julia
# Load base model
base_model = load_model(RxGMMModel, "p300_baseline_v1")

# Collect calibration trials (10-20 per class)
calib_data = BCIData(calib_features, metadata, calib_labels)

# Calibrate model
personalized_model = calibrate_model(
    base_model,
    calib_data;
    iterations = 20  # Fewer iterations needed
)

save_model(personalized_model, "subject_001_p300_calibrated.jld2")
```

**Calibration Benefits:**
- Requires only 10-20 trials per class
- Faster than training from scratch
- Adapts to subject-specific characteristics
- **Hyperparameters preserved**: `calibrate_model()` automatically uses the same hyperparameters as the base model (v0.2.0+)

### 4. Batch Inference

```julia
# Prepare test data
test_data = BCIData(test_features, metadata, test_labels)

# Run batch inference
results = predict_batch(model, test_data; iterations=10)

# Analyze results
println("Predictions: ", results.predictions)
println("Mean confidence: ", mean(results.confidences))

# Calculate metrics
accuracy = sum(results.predictions .== test_labels) / length(test_labels)
println("Accuracy: $(round(accuracy * 100, digits=1))%")
```

### 5. Streaming Inference

```julia
# Initialize streaming session
session = init_streaming(model, metadata_with_chunk_size)

# Process chunks
for chunk in eeg_feature_stream
    result = process_chunk(session, chunk; iterations=10)
    println("Chunk: pred=$(result.prediction), conf=$(round(result.confidence, digits=3))")
end

# Finalize trial
final_result = finalize_trial(session; method=:weighted_vote)
println("Final: pred=$(final_result.prediction), conf=$(round(final_result.confidence, digits=3))")
```

## Hyperparameter Tuning (v0.2.0+)

Fine-tune Bayesian GMM for optimal performance on your specific dataset.

### When to Tune Hyperparameters

Consider tuning when:
- Default performance is unsatisfactory
- You have specific data characteristics (very noisy or very clean)
- You have limited or extensive training data
- Working with complex, overlapping class distributions
- P300 or other paradigms with heterogeneous class variances

### Tuning Strategies

#### For High SNR / Clean Data / Many Trials

Use lower regularization to let the data drive the model:

```julia
model = train_model(
    RxGMMModel,
    train_data;
    iterations = 50,
    dof_offset = 1,                    # Less regularization
    mean_prior_precision = 0.001,      # Weaker prior, trust data more
    predictive_mean_prior = 1e6,       # Standard inference prior
    predictive_dof_offset = 1          # Match dof_offset
)
```

**Use when:**
- SNR > 5 dB
- 100+ trials per class
- Clean, artifact-free data
- Well-controlled experimental conditions

#### For Low SNR / Noisy Data / Few Trials

Use higher regularization for stability (especially important for GMM with class-specific covariances):

```julia
model = train_model(
    RxGMMModel,
    train_data;
    iterations = 50,
    dof_offset = 3,                    # More regularization
    mean_prior_precision = 0.05,       # Stronger prior
    predictive_mean_prior = 1e6,       # Standard inference prior
    predictive_dof_offset = 3          # Match dof_offset
)
```

**Use when:**
- SNR < 2 dB
- 40-80 trials per class
- Noisy data or limited artifact removal
- Challenging recording conditions
- Risk of overfitting to class-specific noise

#### Balanced / Default Settings

The defaults work well for most scenarios:

```julia
model = train_model(
    RxGMMModel,
    train_data;
    iterations = 50,
    dof_offset = 2,                    # Balanced (default)
    mean_prior_precision = 0.01,       # Balanced (default)
    predictive_mean_prior = 1e6,       # Standard (default)
    predictive_dof_offset = 2          # Balanced (default)
)
```

**Use when:**
- Moderate SNR (2-5 dB)
- 80-150 trials per class
- Standard BCI recording conditions
- Starting point for experimentation

### P300-Specific Tuning

For P300 paradigms where target/non-target classes have different variances:

```julia
# P300 often benefits from GMM's class-specific covariances
# Use moderate regularization to avoid overfitting
model = train_model(
    RxGMMModel,
    p300_train_data;
    iterations = 50,
    dof_offset = 2,                    # Standard regularization
    mean_prior_precision = 0.02,       # Slightly stronger than default
    predictive_mean_prior = 1e6,
    predictive_dof_offset = 2
)
```

### Hyperparameter Search Example

Systematically search for optimal hyperparameters:

```julia
using NimbusSDK

# Define search grid
dof_values = [1, 2, 3, 4]
prior_values = [0.001, 0.01, 0.03, 0.05]

# Split data
train_data, val_data = split_data(all_data, ratio=0.8)

best_accuracy = 0.0
best_params = nothing

println("Searching hyperparameters for RxGMM...")
for dof in dof_values
    for prior in prior_values
        # Train model
        model = train_model(
            RxGMMModel,
            train_data;
            iterations = 50,
            dof_offset = dof,
            mean_prior_precision = prior,
            predictive_dof_offset = dof,
            showprogress = false
        )
        
        # Validate
        results = predict_batch(model, val_data)
        accuracy = sum(results.predictions .== val_data.labels) / length(val_data.labels)
        
        println("  dof=$dof, prior=$prior: $(round(accuracy*100, digits=1))%")
        
        if accuracy > best_accuracy
            best_accuracy = accuracy
            best_params = (dof=dof, prior=prior)
        end
    end
end

println("\nBest hyperparameters:")
println("  dof_offset: $(best_params.dof)")
println("  mean_prior_precision: $(best_params.prior)")
println("  Validation accuracy: $(round(best_accuracy*100, digits=1))%")

# Retrain with best params
final_model = train_model(
    RxGMMModel,
    all_data;
    iterations = 50,
    dof_offset = best_params.dof,
    mean_prior_precision = best_params.prior,
    predictive_dof_offset = best_params.dof
)
```

### Quick Tuning Guidelines

| Scenario | `dof_offset` | `mean_prior_precision` | Notes |
|----------|--------------|------------------------|-------|
| **Excellent data quality** | 1 | 0.001 | Minimal regularization |
| **Good data quality** | 2 (default) | 0.01 (default) | Balanced approach |
| **Moderate data quality** | 2-3 | 0.01-0.03 | Slight regularization |
| **Poor data quality** | 3-4 | 0.05-0.1 | Strong regularization |
| **Very limited trials** | 4 | 0.1 | Maximum regularization |
| **P300 target/non-target** | 2 | 0.02 | Moderate, class-specific covariances helpful |

<Tip>
**Pro Tip**: Bayesian GMM's class-specific covariances can overfit to noise with poor data. When in doubt, start with defaults and increase regularization (`dof_offset=3`, `mean_prior_precision=0.03`) if you see overfitting.
</Tip>

<Note>
**Important**: Always set `predictive_dof_offset` to match `dof_offset` for consistency between training and inference phases.
</Note>

## Training Requirements

### Data Requirements

- **Minimum**: 40 trials per class (80 total for 2-class)
- **Recommended**: 80+ trials per class
- **For calibration**: 10-20 trials per class

<Warning>
**Bayesian GMM requires at least 2 observations per class** to estimate class-specific statistics. Training will fail if any class has fewer than 2 observations.
</Warning>

### Feature Normalization

<Tip>
**Critical for cross-session BCI performance!**

Normalize your features before training for 15-30% accuracy improvement across sessions.
</Tip>

```julia
# Estimate normalization from training data
norm_params = estimate_normalization_params(train_features; method=:zscore)
train_norm = apply_normalization(train_features, norm_params)

# Train with normalized features
train_data = BCIData(train_norm, metadata, labels)
model = train_model(RxGMMModel, train_data)

# Save params with model
@save "model.jld2" model norm_params

# Later: Apply same params to test data
test_norm = apply_normalization(test_features, norm_params)
```

See the [Feature Normalization](/inference-configuration/feature-normalization) guide for complete details.

### Feature Requirements

Bayesian GMM expects **preprocessed features**, not raw EEG:

✅ **Required preprocessing:**
- Bandpass filtering (paradigm-specific)
- Artifact removal
- Feature extraction (CSP, ERP amplitude, bandpower, etc.)
- Proper temporal aggregation

❌ **NOT accepted:**
- Raw EEG channels
- Unfiltered data

See [Preprocessing Requirements](/inference-configuration/preprocessing-requirements).

## Performance Characteristics

### Computational Performance

| Operation | Latency | Notes |
|-----------|---------|-------|
| **Training** | 15-40 seconds | 50 iterations, 100 trials per class |
| **Calibration** | 8-20 seconds | 20 iterations, 20 trials per class |
| **Batch Inference** | 15-25ms per trial | 10 iterations |
| **Streaming Chunk** | 15-25ms | 10 iterations per chunk |

Slightly slower than RxLDA due to class-specific covariances.

### Classification Accuracy

| Paradigm | Classes | Typical Accuracy | When to Use Bayesian GMM |
|----------|---------|------------------|-------------------|
| P300 | 2 (Target/Non-target) | 85-95% | Target/non-target have different variances |
| Motor Imagery | 2-4 | 70-85% | When Bayesian LDA accuracy insufficient |
| SSVEP | 2-6 | 85-98% | Complex frequency responses |

<Note>
Bayesian GMM typically provides 2-5% higher accuracy than Bayesian LDA when class covariances differ significantly, at the cost of ~5-10ms additional latency.
</Note>

## Model Inspection

### View Model Parameters

```julia
# Class means
println("Class means:")
for (k, mean) in enumerate(model.means)
    println("  Class $k: ", mean)
end

# Class-specific precisions
println("\nClass-specific precision matrices:")
for (k, prec) in enumerate(model.precisions)
    println("  Class $k (first 3x3):")
    println(prec[1:3, 1:3])
end

# Compare covariances across classes
println("\nCovariance structure comparison:")
for k in 1:length(model.precisions)
    cov_k = inv(model.precisions[k])
    println("  Class $k variance (diagonal): ", diag(cov_k))
end
```

### Visualize Class Differences

```julia
using Plots

# Compare class covariances
for k in 1:length(model.precisions)
    cov_k = inv(model.precisions[k])
    heatmap(cov_k, title="Class $k Covariance", colorbar=true)
end
```

## Advantages & Limitations

### Advantages

✅ **Flexible Modeling**: Each class has its own covariance  
✅ **Better for Complex Data**: Handles heterogeneous distributions  
✅ **Higher Accuracy**: 2-5% improvement when classes differ significantly  
✅ **Uncertainty Quantification**: Full Bayesian posteriors  
✅ **Production-Ready**: Battle-tested in P300 applications  

### Limitations

❌ **More Parameters**: Requires more training data than RxLDA  
❌ **Slower Inference**: ~15-25ms vs ~10-15ms for RxLDA  
❌ **Higher Memory**: Stores n_classes precision matrices  
❌ **More Complex**: Longer training time  

## Comparison: Bayesian GMM vs Bayesian LDA

| Aspect | Bayesian GMM (RxGMM) | Bayesian LDA (RxLDA) |
|--------|-------|-------|
| **Precision Matrix** | Class-specific | Shared (one for all) |
| **Mathematical Model** | Heteroscedastic Gaussian Classifier (HGC) | Pooled Gaussian Classifier (PGC) |
| **Training Speed** | Slower | Faster |
| **Inference Speed** | 15-25ms | 10-15ms |
| **Flexibility** | High | Moderate |
| **Data Requirements** | More | Less |
| **Memory Usage** | Higher | Lower |
| **Best For** | Heterogeneous classes | Homogeneous classes |
| **Accuracy Gain** | +2-5% (when applicable) | Baseline |

### Decision Tree

```
Is speed critical (&lt;15ms)?
├─ Yes → Use Bayesian LDA
└─ No → Do classes have similar spreads?
    ├─ Yes → Use Bayesian LDA (faster, same accuracy)
    └─ No → Use Bayesian GMM (more accurate)
```

## Practical Examples

### P300 Detection

```julia
# Bayesian GMM is ideal for P300 where target/non-target have different variances

# Train on P300 data
p300_data = BCIData(erp_features, p300_metadata, labels)  # 1=target, 2=non-target
model = train_model(RxGMMModel, p300_data; iterations=50)

# Test
results = predict_batch(model, test_data)

# Calculate sensitivity/specificity
targets = test_labels .== 1
target_preds = results.predictions .== 1

sensitivity = sum(target_preds .& targets) / sum(targets)
specificity = sum(.!target_preds .& .!targets) / sum(.!targets)

println("Sensitivity: $(round(sensitivity * 100, digits=1))%")
println("Specificity: $(round(specificity * 100, digits=1))%")
```

### When Bayesian LDA Fails

```julia
# Try Bayesian LDA first
rxlda_model = train_model(RxLDAModel, train_data)
rxlda_results = predict_batch(rxlda_model, test_data)
rxlda_acc = sum(rxlda_results.predictions .== test_labels) / length(test_labels)

# If accuracy insufficient, try Bayesian GMM
if rxlda_acc < 0.75
    println("Bayesian LDA accuracy low ($(round(rxlda_acc*100, digits=1))%), trying Bayesian GMM...")
    rxgmm_model = train_model(RxGMMModel, train_data)
    rxgmm_results = predict_batch(rxgmm_model, test_data)
    rxgmm_acc = sum(rxgmm_results.predictions .== test_labels) / length(test_labels)
    
    println("Bayesian GMM accuracy: $(round(rxgmm_acc*100, digits=1))%")
    println("Improvement: +$(round((rxgmm_acc-rxlda_acc)*100, digits=1))%")
end
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Bayesian LDA (RxLDA)" icon="brain" href="/models/rxlda">
    Faster model with shared covariance
  </Card>
  <Card title="Training Guide" icon="graduation-cap" href="/examples/advanced-applications">
    Complete training tutorial
  </Card>
  <Card title="Julia SDK" icon="code" href="/api-reference/julia-sdk">
    Full SDK reference
  </Card>
  <Card title="Code Examples" icon="brackets-curly" href="/examples/code-samples">
    Working examples
  </Card>
</CardGroup>

## References

**Implementation:**
- RxInfer.jl: https://rxinfer.com/
- Source code: `/src/models/rxgmm/` in NimbusSDK.jl

**Theory:**
- McLachlan, G. J., & Peel, D. (2000). "Finite Mixture Models"
- Bishop, C. M. (2006). "Pattern Recognition and Machine Learning" (Chapter 9)
- Heteroscedastic Gaussian Classifier (HGC) with class-specific covariances

**BCI Applications:**
- Farwell, L. A., & Donchin, E. (1988). "Talking off the top of your head"
- Lotte et al. (2018). "A review of classification algorithms for EEG-based BCI"
