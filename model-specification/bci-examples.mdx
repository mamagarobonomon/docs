---
title: "BCI Model Examples"
description: "Detailed examples of BCI paradigms with Nimbus models"
icon: "beaker"
---

# BCI Model Examples

<Warning>
**Note**: This page describes **conceptual probabilistic models** for educational purposes. NimbusSDK currently implements **RxLDA** and **RxGMM** models. The examples below illustrate the theoretical foundations that inform these implementations.

For **working code examples**, see:
- [Code Samples](/examples/code-samples) - Julia SDK examples
- [Basic Examples](/examples/basic-examples) - RxLDA/RxGMM applications
- [Advanced Applications](/examples/advanced-applications) - Advanced RxLDA/RxGMM usage
</Warning>

## Motor Imagery: Theoretical Model

### Conceptual Probabilistic Model

Motor imagery BCI can be understood through this probabilistic lens:

$$
p(\text{class}, \text{features}) = p(\text{class}) \cdot p(\text{features}|\text{class})
$$

**Components:**
1. **Prior**: $ p(\text{class}) $ - Equal probability for each motor imagery class (left, right, feet, tongue)
2. **Likelihood**: $ p(\text{features}|\text{class}) $ - Gaussian distribution of EEG features given the class
3. **Posterior**: $ p(\text{class}|\text{features}) $ - Computed via Bayes' rule

### RxLDA Implementation

NimbusSDK implements this using **RxLDA** with shared covariance:

```julia
using NimbusSDK

# Load pre-trained RxLDA motor imagery model
model = load_model(RxLDAModel, "motor_imagery_4class_v1")

# Or train from scratch
metadata = BCIMetadata(
    sampling_rate = 250.0,
    paradigm = :motor_imagery,
    feature_type = :csp,
    n_features = 16,
    n_classes = 4
)

features = randn(16, 250, 100)  # 100 trials
labels = rand(1:4, 100)  # 4 classes
training_data = BCIData(features, metadata, labels)

# Train model - learns μ₁, μ₂, μ₃, μ₄ and shared Σ
trained_model = train_model(RxLDAModel, training_data; iterations=50)

# Inference
test_data = BCIData(test_features, metadata)
results = predict_batch(trained_model, test_data)
```

**Mathematical Model:**

$$
p(x|c) = \mathcal{N}(x | \mu_c, \Sigma)
$$

Where:
- $ x $: CSP-extracted features (16-dimensional)
- $ c \in \{1,2,3,4\} $: Motor imagery class
- $ \mu_c $: Class-specific mean (learned from data)
- $ \Sigma $: Shared covariance matrix (learned from data)

### Performance Expectations

<Card title="Motor Imagery with RxLDA" icon="brain">
  **Typical Accuracy**: 70-85% for 4-class MI  
  **Calibration Time**: 5-10 minutes (50-100 trials)  
  **Inference Latency**: 10-20ms per trial  
  **ITR**: 15-25 bits/minute (4-second trials)  
</Card>

## P300 Detection: Theoretical Model

### Conceptual Probabilistic Model

P300 detection distinguishes target from non-target stimuli:

$$
p(\text{target}, \text{ERP features}) = p(\text{target}) \cdot p(\text{ERP}|\text{target})
$$

**Components:**
1. **Prior**: $ p(\text{target}) $ - Low probability (e.g., 1/6 for 6×6 speller)
2. **Likelihood**: $ p(\text{ERP}|\text{target}) $ - Gaussian distribution with P300 component
3. **Posterior**: $ p(\text{target}|\text{ERP}) $ - Target probability given ERP

### RxGMM Implementation

NimbusSDK uses **RxGMM** for flexible P300 detection:

```julia
using NimbusSDK

# Load pre-trained P300 model
model = load_model(RxGMMModel, "p300_binary_v1")

# Or train from scratch
metadata = BCIMetadata(
    sampling_rate = 250.0,
    paradigm = :p300,
    feature_type = :erp,
    n_features = 12,  # ERP amplitudes from 12 channels
    n_classes = 2  # target vs non-target
)

# Training data: post-stimulus ERP features
features = randn(12, 200, 150)  # 150 epochs, 0.8s post-stimulus
labels = rand(1:2, 150)  # 1=target, 2=non-target
training_data = BCIData(features, metadata, labels)

# Train - learns μ₁, Σ₁ (target) and μ₂, Σ₂ (non-target)
trained_model = train_model(RxGMMModel, training_data; iterations=50)

# Inference
results = predict_batch(trained_model, test_data)
```

**Mathematical Model:**

$$
p(x|\text{target}) = \mathcal{N}(x | \mu_{\text{target}}, \Sigma_{\text{target}})
$$
$$
p(x|\text{non-target}) = \mathcal{N}(x | \mu_{\text{non-target}}, \Sigma_{\text{non-target}})
$$

Where:
- $ x $: ERP features (12-dimensional)
- Class-specific means and covariances capture P300 morphology

### Performance Expectations

<Card title="P300 Detection with RxGMM" icon="signal">
  **Typical Accuracy**: 85-95% binary detection  
  **Calibration Time**: 3-5 minutes (100-150 epochs)  
  **Inference Latency**: 15-25ms per epoch  
  **ITR**: 10-20 bits/minute (with 10 repetitions)  
</Card>

## Online Learning (Available Now)

Both Python and Julia SDKs support online learning for model adaptation:

### Python SDK

```python
from nimbus_pysdk import NimbusLDA

# Initial training
clf = NimbusLDA()
clf.fit(X_train, y_train)

# Online adaptation with new data
clf.partial_fit(X_new, y_new)
```

### Julia SDK

```julia
using NimbusSDK

# Initial training
model = train_model(RxLDAModel, train_data)

# Update with new data
updated_model = update_model(model, new_data)
```

**Benefits:**
- Adapt to changing brain states
- Personalization over time
- No full retraining required

## Current SDK Capabilities

<CardGroup cols={2}>
  <Card title="✅ Bayesian LDA" icon="check">
    Motor imagery, P300, any classification task
  </Card>
  <Card title="✅ Bayesian GMM" icon="check">
    Flexible classification with class-specific covariances
  </Card>
  <Card title="✅ Bayesian Softmax/MPR" icon="check">
    Multinomial logistic regression for complex boundaries
  </Card>
  <Card title="✅ Model Training" icon="check">
    Supervised training on labeled data
  </Card>
  <Card title="✅ Model Calibration" icon="check">
    Subject-specific adaptation
  </Card>
  <Card title="✅ Online Learning" icon="check">
    Incremental updates with partial_fit (Python) or update_model (Julia)
  </Card>
  <Card title="✅ Streaming Inference" icon="check">
    Real-time chunk-by-chunk processing
  </Card>
  <Card title="✅ Quality Assessment" icon="check">
    Entropy, calibration metrics, ITR calculation
  </Card>
</CardGroup>

## Working Examples

For **actual working code** with Bayesian LDA (RxLDA), Bayesian GMM (RxGMM), and Bayesian MPR (RxPolya):

<CardGroup cols={2}>
  <Card title="Code Samples" icon="code" href="/examples/code-samples">
    Complete Julia examples
  </Card>
  <Card title="Basic Examples" icon="play" href="/examples/basic-examples">
    Motor imagery & P300
  </Card>
  <Card title="Advanced Applications" icon="rocket" href="/examples/advanced-applications">
    Calibration, adaptation, hybrid systems
  </Card>
  <Card title="Batch Processing" icon="layers" href="/inference-configuration/batch-processing">
    Training and evaluation
  </Card>
</CardGroup>

---

<Note>
**Purpose of This Page**: This page provides **conceptual foundations** for understanding probabilistic BCI models. For **practical implementation**, use the working Bayesian LDA (RxLDA), Bayesian GMM (RxGMM), and Bayesian MPR (RxPolya) models documented in the examples and API reference.
</Note>
